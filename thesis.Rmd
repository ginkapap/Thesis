---
title: "二一預測模型建構－以國立臺北大學日間部學士班為例"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: yes
      smooth_scroll: no
  word_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,fig.showtext=TRUE, results = "hide",warning = FALSE)
library(dplyr)
library(knitr)
library(magrittr)
library(kableExtra)
library(DT)
library(stringr)
library(readr)
library(htmltools)
library(ggplot2)
library(purrr)
library(lubridate)
library(tidyr)
library(showtext)
library(ggridges)
library(GGally)
library(caret)
library(plotROC)
library(DMwR)
library(ROSE)
library(rpart.plot)
#font_add("QYuan","cwTeXQYuan-Medium.ttf")
showtext_auto(enable=TRUE)
theme_set(theme_classic())
```
```{r}
library("reticulate")
use_condaenv("ginkapap")
#conda_install(envname = "ginkapap",c("pandas"))
#conda_install(envname = "ginkapap",c("keras",'tensorflow'))
#py_available()
```
```{r 定義合成圖公式}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```
```{python 匯入資料}
import pandas as pd
import numpy as np
df = pd.read_csv('~/Dropbox/M-Team/research-transcript-and-student-types/main_student2.csv')
df['實拿學分'] = np.where(df['學期成績'] >= 60, df['學分數'], 0)
#刪掉所有系級年級數並保留法律系各組
df['系別'] = np.where(df['系級'].astype(str).str[0] == '法','法律學系',df['系別'])
df['開課系所'] = np.where(df['開課系所'].str[0] == '(',df['開課系所'].str[4:],df['開課系所'])
df['班別'] = df['班別'].fillna('無')
df['ClassId'] = df['科目名稱'] + df['學年'].astype(str) + df['學期'].astype(str)
#入學年
df['入學年'] = df['學號'].astype(str).str[1:4]
#去掉修課不滿八學期者
#dftest = pd.DataFrame(df.groupby(['學號',"學期",'學年']).size().reset_index())
#dftest = pd.DataFrame(dftest.groupby(['學號']).size().reset_index(name='修課幾學期'))
#dfcomplete = pd.merge(df,dftest,on='學號') 
#df = dfcomplete[dfcomplete['修課幾學期'] >= 8]
df=df[df['系別'].str[0] != '(']
df = df[(df['入學年'] != '998') & (df['入學年'] != '997') & (df['入學年'] != '967') & (df['入學年'] != '968')& (df['入學年'] != '977') & (df['入學年'] != '978') & (df['入學年'] != '987') & (df['入學年'] != '988')]
```
```{python 體育課名統一}
#計算各班人數
dfnum = df.groupby(['系別','入學年','學號']).size().reset_index()
#print(dfnum)
dfnum = dfnum.groupby(['系別','入學年','學號']).size().reset_index(name = 'x')
#print(dfnum)
dfnum = dfnum.groupby(['系別','入學年']).size().reset_index(name = '該班人數')
#print(dfnum)
df = pd.merge(df,dfnum,on=['系別','入學年'],how='left')
#將體育課名統一化
df['名稱'] = np.where(df['科目名稱'].str[:2] == '體育', '體育',df['科目名稱'])
df['ClassId'] = df['名稱'] + df['學年'].astype(str) + df['學期'].astype(str)
#df['ClassId'] = np.where(df['ClassId'].str[:2] == '體育', '體育',df['ClassId'])
```
```{python,eval=FALSE}
#秀出97、98年入學者資料有幾筆
df9798 = df.groupby(['學號','入學年','系別']).size().reset_index(name='人數')
#df9798 = df9798.groupby(['入學年','系別']).size().reset_index(name='人數')
#df9798 =  df9798[(df9798['入學年'] == '998') | (df9798['入學年'] == '997') | (df9798['入學年'] == '967') | (df9798['入學年'] == '968') | (df9798['入學年'] == '977') | (df9798['入學年'] == '978') | (df9798['入學年'] == '987') | (df9798['入學年'] == '988')]

#df = df[(df['入學年'] != '998') & (df['入學年'] != '997') & (df['入學年'] != '967') & (df['入學年'] != '968')& (df['入學年'] != '977') & (df['入學年'] != '978') & (df['入學年'] != '987') & (df['入學年'] != '988')]
```
```{python 被解釋21標籤}
df21 = df.groupby(['學號','學年','學期'])['實拿學分','學分數'].sum().reset_index()
df21['是否被二一'] = np.where(df21['實拿學分']/df21['學分數'] <= 1/2 ,1 ,0)
df21=df21.drop(['實拿學分','學分數'],axis=1)
df=pd.merge(df,df21,on = ['學號','學年','學期'],how='outer')
```
```{python 二一圖}
#沒去掉修課不滿八學期者
dftestt = pd.DataFrame(df.groupby(['學號',"學期",'學年']).size().reset_index())
dftestt = pd.DataFrame(dftestt.groupby(['學號']).size().reset_index(name='修課幾學期'))
df = pd.merge(df,dftestt,on='學號') 
dfpic = df.copy()
```

```{python}
print(dfpic.groupby(['學號']).count().reset_index())#4941位學生

dfpic_1 = dfpic[dfpic['是否被二一']==1]#成績資料
df2 = dfpic_1.groupby(['學號','學年','學期','系別','是否被二一','入學年']).size().reset_index()
df3 = df2.groupby(['學號']).size().reset_index(name = '二一次數')
df4 = df3.groupby('二一次數').size().reset_index(name = '人數')
####
#dfpic4_1=dfpic.groupby(['學號','學年','學期'])['是否被二一'].mean().reset_index()
#dfpic4_1['是否被二一'] = dfpic4_1['是否被二一'].astype(str)
```
```{python }
dfpic2 = dfpic.groupby(['學號','入學年','是否被二一']).size().reset_index(name='t')
dfpic2['是否被二一']=dfpic2['是否被二一'].astype(int)
dfpic2_1 = dfpic2.groupby(['學號','入學年'])['是否被二一'].sum().reset_index(name='二一')
dfpic2_1['二一']=dfpic2_1['二一'].astype(str)
dfpic2_1['入學年']=dfpic2_1['入學年'].astype(str)
```
```{python 是否被二一過}
df['年級'] = df['系級'].str[-1] + df['學期'].astype(str)
df21cum = df.groupby(['學號','年級','系別','是否被二一']).size().reset_index(name='t')
df21cum['是否被二一']=df21cum['是否被二一'].astype(int)
df21cum1 = df21cum.groupby(['學號','年級','系別'])['是否被二一'].sum().reset_index(name='二一')
df21cum1['累積二一'] =df21cum1.groupby(['學號'])['二一'].apply(lambda x: x.cumsum().shift())
df21cum1=df21cum1.fillna(0)
df21cum1 = df21cum1.drop(['二一'],axis=1)
df=pd.merge(df,df21cum1,on=['學號','年級','系別'],how='outer')
```
```{python 圖}
dfpic['年級'] = dfpic['系級'].str[-1] + dfpic['學期'].astype(str)
dfpic3 = dfpic.groupby(['學號','年級','系別','是否被二一']).size().reset_index(name='t')
dfpic3['是否被二一']=dfpic3['是否被二一'].astype(int)
dfpic3_1 = dfpic3.groupby(['學號','年級','系別'])['是否被二一'].sum().reset_index(name='二一')
dfpic3_1 = dfpic3_1[dfpic3_1['二一']==1]
dfpic3_1 = dfpic3_1[(dfpic3_1['年級'] != '11')]
#dfpic3_4 = pd.merge(dfpic3_2,dfpic3_3,on='學號',how='left')

#dfpic3_4 = dfpic3_4.groupby(['學號'])['real'].mean().reset_index(name='二一')
#dfpic3_4 = dfpic3_4[dfpic3_4['real'] >=2]

dfpic3_1['累積二一'] =dfpic3_1.groupby(['學號'])['二一'].apply(lambda x: x.cumsum())
dfpic3_1=dfpic3_1.fillna(0)
dfpic3_1['累積二一'] = dfpic3_1['累積二一'].astype(int)
dfpic3_1['累積二一'] = np.where(dfpic3_1['累積二一'] >2 ,'3次以上',dfpic3_1['累積二一'])
dfpic3_1['累積二一'] = dfpic3_1['累積二一'].astype(str)
```
```{python 貼上累計專業必修被當比特徵}
#計算各系專業必修
#貼上特徵
dfrequired = df[(df['必選修類別（必／選／通）']=='必') & (df['開課系所'] != '軍訓（必選修）') &(df['名稱'] != '體育') & (df['科目名稱'] !='大一國文：經典閱讀與詮釋') &(df['科目名稱'] !='國文：經典閱讀與詮釋') & (df['科目名稱'] !='大學英文：英語聽講練習')  & (df['科目名稱'] !='大學英文') & (df['科目名稱'] !='英語聽講練習') & (df['科目名稱'] !='英文') & (df['科目名稱'] !='歷史') ]
dfrequired_1 = dfrequired.groupby(['科目名稱','系別','入學年']).size().reset_index(name = '該課被該班修過幾次')
dfrequired = pd.merge(dfrequired,dfrequired_1,on=['科目名稱','系別','入學年'],how='left')
#若該班修課人數>該班人數的5成則那門課算為必修課
dfrequired['是否為專業必修'] = np.where((dfrequired['該課被該班修過幾次']/dfrequired['該班人數']) >= 0.5 , 1 , 0)
dfrequired = dfrequired[['系別','科目名稱','入學年','是否為專業必修']]
dfrequired = dfrequired.groupby(['系別','科目名稱','入學年'])['是否為專業必修'].mean().reset_index()
df = pd.merge(df,dfrequired,on=['系別','科目名稱','入學年'],how='outer')
df = df.fillna(0)
#必修不及格各學期狀況
df['不及格']=np.where(df['學期成績'] < 60 , 1 , 0)
dfrequired=df[df['是否為專業必修'] == 1]
dfrequiredg1=dfrequired.groupby(['學號','學年','學期'])['不及格'].sum().reset_index(name = '專業必修被當')
df= pd.merge(df,dfrequiredg1,on=['學號','學年','學期'],how='outer')
#fill na 0
df=df.fillna(0)
#製作累積
dfrequiredg2 = df.groupby(['學號','學年','學期'])['專業必修被當'].mean().reset_index()
dfrequiredg2['累積專業必修被當'] =dfrequiredg2.groupby(['學號'])['專業必修被當'].apply(lambda x: x.cumsum().shift())
#製作圖的累積
dfrequiredg2['累積專業必修被當pic'] =dfrequiredg2.groupby(['學號'])['專業必修被當'].apply(lambda x: x.cumsum())
#fill na 0
dfrequiredg2 = dfrequiredg2[['學號','學年','學期','累積專業必修被當','累積專業必修被當pic']]
dfrequiredg2= dfrequiredg2.fillna(0)
df=pd.merge(df,dfrequiredg2,on = ['學號','學年','學期'],how='outer')
#製作當學期必修課
dfrequiredg3=dfrequired.groupby(['學號','學年','學期']).size().reset_index(name = '當學期專業必修修課數')
df = pd.merge(df,dfrequiredg3,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
#製作累計
dfrequiredg3 = df.groupby(['學號','學年','學期'])['當學期專業必修修課數'].mean().reset_index()
dfrequiredg3['累積專業必修修課數'] =dfrequiredg3.groupby(['學號'])['當學期專業必修修課數'].apply(lambda x: x.cumsum().shift())
dfrequiredg3['累積專業必修修課數pic'] =dfrequiredg3.groupby(['學號'])['當學期專業必修修課數'].apply(lambda x: x.cumsum())
dfrequiredg3 = dfrequiredg3.drop('當學期專業必修修課數',axis=1)
dfrequiredg3 = dfrequiredg3.fillna(0)
df=pd.merge(df,dfrequiredg3,on = ['學號','學年','學期'],how='outer')
#被當比
df['累積專業必修被當比'] = df['累積專業必修被當'] / df['累積專業必修修課數']
df['累積專業必修被當比pic'] = df['累積專業必修被當pic'] / df['累積專業必修修課數pic']
df = df.fillna(0)
```
```{python 必圖}
dfpic4 = df.copy()
dfpic4 = dfpic4.drop_duplicates()
dfpic4['年級'] = dfpic4['系級'].str[-1] + dfpic4['學期'].astype(str)
dfpic4 = dfpic4[dfpic4['年級'] != '11']
#print(dfclass1_1_1[dfclass1_1_1['學號']==410071464])
dfpic4 = dfpic4.groupby(['學號','學年','學期','年級','是否被二一'])['累積專業必修被當比pic'].mean().reset_index(name='累積專業必修被當比')
dfpic4['是否被二一'] = dfpic4['是否被二一'].astype(str)
```
```{python 貼上累積共同必修特徵}
dfcommon= df[(df['名稱'] == '體育') |(df['科目名稱'] =='大一國文：經典閱讀與詮釋') |(df['科目名稱'] =='國文：經典閱讀與詮釋') | (df['科目名稱'] =='大學英文：英語聽講練習')  | (df['科目名稱'] =='大學英文') | (df['科目名稱'] =='英語聽講練習') | (df['科目名稱'] =='英文') | (df['科目名稱'] =='歷史')]
dfcommon = dfcommon[(dfcommon['必選修類別（必／選／通）']=='必')]
#共同必修不及格各學期狀況
dfcommon1 = dfcommon.groupby(['學號','學年','學期'])['不及格'].sum().reset_index(name = '共同必修被當')
df= pd.merge(df,dfcommon1,on=['學號','學年','學期'],how='outer')
#fill na 0
df=df.fillna(0)
#製作累積
dfcommong2 = df.groupby(['學號','學年','學期'])['共同必修被當'].mean().reset_index()
dfcommong2['累積共同必修被當'] = dfcommong2.groupby(['學號'])['共同必修被當'].apply(lambda x: x.cumsum().shift())
#製作圖的累積
dfcommong2['累積共同必修被當pic'] =dfcommong2.groupby(['學號'])['共同必修被當'].apply(lambda x: x.cumsum())
#fill na 0
dfcommong2 = dfcommong2[['學號','學年','學期','累積共同必修被當','累積共同必修被當pic']]
dfcommong2= dfcommong2.fillna(0)
df=pd.merge(df,dfcommong2,on = ['學號','學年','學期'],how='outer')
#製作當學期必修課
dfcommong3=dfcommon.groupby(['學號','學年','學期']).size().reset_index(name = '當學期共同必修修課數')
df = pd.merge(df,dfcommong3,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
#製作累計
dfcommong3 = df.groupby(['學號','學年','學期'])['當學期共同必修修課數'].mean().reset_index()
dfcommong3['累積共同必修修課數'] =dfcommong3.groupby(['學號'])['當學期共同必修修課數'].apply(lambda x: x.cumsum().shift())
dfcommong3['累積共同必修修課數pic'] =dfcommong3.groupby(['學號'])['當學期共同必修修課數'].apply(lambda x: x.cumsum())
dfcommong3 = dfcommong3.drop('當學期共同必修修課數',axis=1)
dfcommong3 = dfcommong3.fillna(0)
df=pd.merge(df,dfcommong3,on = ['學號','學年','學期'],how='outer')
#被當比
df['累積共同必修被當比'] = df['累積共同必修被當'] / df['累積共同必修修課數']
df['累積共同必修被當比pic'] = df['累積共同必修被當pic'] / df['累積共同必修修課數pic']
df = df.fillna(0)
```
```{python 共必圖}
dfpic4_1 = df.copy()
dfpic4_1['年級'] = dfpic4_1['系級'].str[-1] + dfpic4_1['學期'].astype(str)
dfpic4_1 = dfpic4_1[dfpic4_1['年級'] != '11']
dfpic4_1 = dfpic4_1.groupby(['學號','學年','學期','年級','是否被二一'])['累積共同必修被當比pic'].mean().reset_index(name='累積共同必修被當比')
dfpic4_1['是否被二一'] = dfpic4_1['是否被二一'].astype(str)
```
```{python 貼上累積其他必修特徵}
dfothers = df[(df['開課系所'] != '軍訓（必選修）') &(df['名稱'] != '體育') & (df['科目名稱'] !='大一國文：經典閱讀與詮釋') &(df['科目名稱'] !='國文：經典閱讀與詮釋') & (df['科目名稱'] !='大學英文：英語聽講練習')  & (df['科目名稱'] !='大學英文') & (df['科目名稱'] !='英語聽講練習') & (df['科目名稱'] !='英文') & (df['科目名稱'] !='歷史') ]
dfothers = dfothers[(dfothers['必選修類別（必／選／通）']=='必')]
dfothers = dfothers[dfothers['是否為專業必修'] != 1]
#其他必修不及格各學期狀況
dfothers1 = dfothers.groupby(['學號','學年','學期'])['不及格'].sum().reset_index(name = '其他必修被當')
df= pd.merge(df,dfothers1,on=['學號','學年','學期'],how='outer')
#fill na 0
df=df.fillna(0)
#製作累積
dfothersg2 = df.groupby(['學號','學年','學期'])['其他必修被當'].mean().reset_index()
dfothersg2['累積其他必修被當'] = dfothersg2.groupby(['學號'])['其他必修被當'].apply(lambda x: x.cumsum().shift())
#製作圖的累積
dfothersg2['累積其他必修被當pic'] =dfothersg2.groupby(['學號'])['其他必修被當'].apply(lambda x: x.cumsum())
#fill na 0
dfothersg2 = dfothersg2[['學號','學年','學期','累積其他必修被當','累積其他必修被當pic']]
dfothersg2= dfothersg2.fillna(0)
df=pd.merge(df,dfothersg2,on = ['學號','學年','學期'],how='outer')
#製作當學期必修課
dfothersg3=dfothers.groupby(['學號','學年','學期']).size().reset_index(name = '當學期其他必修修課數')
df = pd.merge(df,dfothersg3,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
#製作累計
dfothersg3 = df.groupby(['學號','學年','學期'])['當學期其他必修修課數'].mean().reset_index()
dfothersg3['累積其他必修修課數'] =dfothersg3.groupby(['學號'])['當學期其他必修修課數'].apply(lambda x: x.cumsum().shift())
dfothersg3['累積其他必修修課數pic'] =dfothersg3.groupby(['學號'])['當學期其他必修修課數'].apply(lambda x: x.cumsum())
dfothersg3 = dfothersg3.drop('當學期其他必修修課數',axis=1)
dfothersg3 = dfothersg3.fillna(0)
df=pd.merge(df,dfothersg3,on = ['學號','學年','學期'],how='outer')
#被當比
df['累積其他必修被當比'] = df['累積其他必修被當'] / df['累積其他必修修課數']
df['累積其他必修被當比pic'] = df['累積其他必修被當pic'] / df['累積其他必修修課數pic']
df = df.fillna(0)
```
```{python 其他必圖}
dfpic4_2 = df.copy()
dfpic4_2['年級'] = dfpic4_2['系級'].str[-1] + dfpic4_2['學期'].astype(str)
dfpic4_2 = dfpic4_2[dfpic4_2['年級'] != '11']
#print(dfclass1_1_1[dfclass1_1_1['學號']==410071464])
dfpic4_2 = dfpic4_2.groupby(['學號','學年','學期','年級','是否被二一'])['累積其他必修被當比pic'].mean().reset_index(name='累積其他必修被當比')
dfpic4_2['是否被二一'] = dfpic4_2['是否被二一'].astype(str)
```
```{python 計算選修中位數,eval=FALSE}
#### 累計選修被當比
#計算每人選修課數、 各班中位數
dfclass2 = df[(df['必選修類別（必／選／通）'] == '選') & (df['不及格'] != 1)]
dfclass2 = dfclass2.groupby(['系別','入學年','學號']).size().reset_index(name = '個人選修數')
dfclass2 = dfclass2.groupby(['系別','入學年'])['個人選修數'].median().reset_index(name = '班選修中位數')
dfclass2=dfclass2[(dfclass2['入學年']=='100') |(dfclass2['入學年']=='101') | (dfclass2['入學年']=='102') |
(dfclass2['入學年']=='103')]
```
```{python 貼上累計選修被當比特徵}
#貼上特徵
#選修不及格各學期狀況
dfclass2_1=df[df['必選修類別（必／選／通）'] == '選']
dfclass2_1_1=dfclass2_1.groupby(['學號','學年','學期'])['不及格'].sum().reset_index(name = '選修被當')
df = pd.merge(df,dfclass2_1_1,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
dfclass2_1_1 = df.groupby(['學號','學年','學期'])['選修被當'].mean().reset_index()
dfclass2_1_1['累積選修被當'] =dfclass2_1_1.groupby(['學號'])['選修被當'].apply(lambda x: x.cumsum().shift())
dfclass2_1_1['累積選修被當pic'] =dfclass2_1_1.groupby(['學號'])['選修被當'].apply(lambda x: x.cumsum())
dfclass2_1_1 = dfclass2_1_1.fillna(0)
dfclass2_1_2=dfclass2_1.groupby(['學號','學年','學期']).size().reset_index(name = '當學期選修修課數')
df = pd.merge(df,dfclass2_1_2,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
dfclass2_1_2 = df.groupby(['學號','學年','學期'])['當學期選修修課數'].mean().reset_index()
dfclass2_1_2['累積選修修課數'] =dfclass2_1_2.groupby(['學號'])['當學期選修修課數'].apply(lambda x: x.cumsum().shift())
dfclass2_1_2['累積選修修課數pic'] =dfclass2_1_2.groupby(['學號'])['當學期選修修課數'].apply(lambda x: x.cumsum())
dfclass2_1_2 = dfclass2_1_2.drop(['當學期選修修課數'],axis=1)
dfclass2_1_2 = dfclass2_1_2.fillna(0)
dfclass2_1_3=pd.merge(dfclass2_1_2,dfclass2_1_1,on = ['學號','學年','學期'])
dfclass2_1_3['累積選修被當比'] = dfclass2_1_3['累積選修被當'] / dfclass2_1_3['累積選修修課數']
dfclass2_1_3['累積選修被當比pic'] = dfclass2_1_3['累積選修被當pic'] / dfclass2_1_3['累積選修修課數pic']
dfclass2_1_3 = dfclass2_1_3.drop(['選修被當'],axis =1)
dfclass2_1_3=dfclass2_1_3.fillna(0)
df=pd.merge(df,dfclass2_1_3,on = ['學號','學年','學期'],how='outer')
```
```{python}
dfpic5 = df.copy()
dfpic5['年級'] = dfpic5['系級'].str[-1] + dfpic5['學期'].astype(str)
dfpic5 = dfpic5[dfpic5['年級'] != '11']
dfpic5 = dfpic5.groupby(['學號','學年','學期','年級','是否被二一'])['累積選修被當比pic'].mean().reset_index(name='累積選修被當比')
dfpic5['是否被二一'] = dfpic5['是否被二一'].astype(str)
```
```{python 計算通識中位數 ＊＊有些達到8、9＊＊}
#通識
#計算每人通識課數、 各班中位數
dfclass3 = df[(df['必選修類別（必／選／通）'] == '通') &(df['不及格'] != 1)]
dfclass3 = dfclass3.groupby(['系別','入學年','學號']).size().reset_index(name = '個人通識數')
dfclass3 = dfclass3.groupby(['系別','入學年'])['個人通識數'].median().reset_index(name = '班通識中位數')
dfclass3=dfclass3[(dfclass3['入學年']=='100') |(dfclass3['入學年']=='101') | (dfclass3['入學年']=='102') |
(dfclass3['入學年']=='103')]
```
```{python 貼上累計通識被當比特徵}
#貼上特徵
dfclass3_1=df[df['必選修類別（必／選／通）'] == '通']
dfclass3_1_1=dfclass3_1.groupby(['學號','學年','學期'])['不及格'].sum().reset_index(name = '通識被當')
df = pd.merge(df,dfclass3_1_1,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
dfclass3_1_1 = df.groupby(['學號','學年','學期'])['通識被當'].mean().reset_index()
dfclass3_1_1['累積通識被當'] =dfclass3_1_1.groupby(['學號'])['通識被當'].apply(lambda x: x.cumsum().shift())
dfclass3_1_1['累積通識被當pic'] =dfclass3_1_1.groupby(['學號'])['通識被當'].apply(lambda x: x.cumsum())
dfclass3_1_1 = dfclass3_1_1.fillna(0)
dfclass3_1_2=dfclass3_1.groupby(['學號','學年','學期']).size().reset_index(name = '當學期通識修課數')
df = pd.merge(df,dfclass3_1_2,on=['學號','學年','學期'],how='outer')
df=df.fillna(0)
dfclass3_1_2 = df.groupby(['學號','學年','學期'])['當學期通識修課數'].mean().reset_index()
dfclass3_1_2['累積通識修課數'] =dfclass3_1_2.groupby(['學號'])['當學期通識修課數'].apply(lambda x: x.cumsum().shift())
dfclass3_1_2['累積通識修課數pic'] =dfclass3_1_2.groupby(['學號'])['當學期通識修課數'].apply(lambda x: x.cumsum())
dfclass3_1_2 = dfclass3_1_2.drop(['當學期通識修課數'],axis=1)
dfclass3_1_2 = dfclass3_1_2.fillna(0)
dfclass3_1_3=pd.merge(dfclass3_1_2,dfclass3_1_1,on = ['學號','學年','學期'])
dfclass3_1_3['累積通識被當比'] = dfclass3_1_3['累積通識被當'] / dfclass3_1_3['累積通識修課數']
dfclass3_1_3['累積通識被當比pic'] = dfclass3_1_3['累積通識被當pic'] / dfclass3_1_3['累積通識修課數pic']
dfclass3_1_3 = dfclass3_1_3.drop(['通識被當'],axis =1)
dfclass3_1_3=dfclass3_1_3.fillna(0)
df=pd.merge(df,dfclass3_1_3,on = ['學號','學年','學期'],how='outer')
```
```{python}
dfpic6 = df.copy()
dfpic6['年級'] = dfpic6['系級'].str[-1]+dfpic6['學期'].astype(str)
dfpic6 = dfpic6[dfpic6['年級'] != '11']
dfpic6 = dfpic6.groupby(['學號','學年','學期','年級','是否被二一'])['累積通識被當比pic'].mean().reset_index(name='累積通識被當比')
dfpic6['是否被二一'] = dfpic6['是否被二一'].astype(str)
```

```{python 製作專業必修成績表現}
#定義專業
df25 = df[df['是否為專業必修'] == 1]
#成績
df25_1 = df25.groupby(['學號','年級'])['學期成績'].sum().reset_index(name='學期成績加總')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積成績
df23 = df.groupby(['學號','年級'])['學期成績加總'].mean().reset_index()
df23['累積成績加總'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum().shift())
df23['累積成績加總pic'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積成績加總','累積成績加總pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#科目
df25_1 = df25.groupby(['學號','年級'])['科目名稱'].count().reset_index(name='學期科目數')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積科目
df23 = df.groupby(['學號','年級'])['學期科目數'].mean().reset_index()
df23['累積科目數'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum().shift())
df23['累積科目數pic'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積科目數','累積科目數pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#累積平均
df['累積平均成績'] = df['累積成績加總']/df['累積科目數']
df['累積平均成績pic'] = df['累積成績加總pic']/df['累積科目數pic']
#pr比較
df = df.fillna(0)
df = df.assign(累積專業排名=df.groupby(['系別','年級','入學年'])['累積平均成績'].rank(pct=True).mul(100))
df = df.assign(累積專業排名pic=df.groupby(['系別','年級','入學年'])['累積平均成績pic'].rank(pct=True).mul(100))
#丟棄多餘變數
df=df.drop(['累積科目數','累積科目數pic','學期成績加總','學期科目數','累積平均成績','累積平均成績pic','累積成績加總','累積成績加總pic'],axis=1)
```

```{python 製作共同必修成績表現}
#定義共同
df251= df[(df['名稱'] == '體育') |(df['科目名稱'] =='大一國文：經典閱讀與詮釋') |(df['科目名稱'] =='國文：經典閱讀與詮釋') | (df['科目名稱'] =='大學英文：英語聽講練習')  | (df['科目名稱'] =='大學英文') | (df['科目名稱'] =='英語聽講練習') | (df['科目名稱'] =='英文') | (df['科目名稱'] =='歷史')]
df251 = df251[(df251['必選修類別（必／選／通）']=='必')]
#成績
df25_1 = df251.groupby(['學號','年級'])['學期成績'].sum().reset_index(name='學期成績加總')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積成績
df23 = df.groupby(['學號','年級'])['學期成績加總'].mean().reset_index()
df23['累積成績加總'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum().shift())
df23['累積成績加總pic'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積成績加總','累積成績加總pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#科目
df25_1 = df251.groupby(['學號','年級'])['科目名稱'].count().reset_index(name='學期科目數')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積科目
df23 = df.groupby(['學號','年級'])['學期科目數'].mean().reset_index()
df23['累積科目數'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum().shift())
df23['累積科目數pic'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積科目數','累積科目數pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#累積平均
df['累積平均成績'] = df['累積成績加總']/df['累積科目數']
df['累積平均成績pic'] = df['累積成績加總pic']/df['累積科目數pic']
#pr比較
df = df.fillna(0)
df = df.assign(累積共同排名=df.groupby(['系別','年級','入學年'])['累積平均成績'].rank(pct=True).mul(100))
df = df.assign(累積共同排名pic=df.groupby(['系別','年級','入學年'])['累積平均成績pic'].rank(pct=True).mul(100))
#丟棄多餘變數
df=df.drop(['累積科目數','累積科目數pic','學期成績加總','學期科目數','累積平均成績','累積平均成績pic','累積成績加總','累積成績加總pic'],axis=1)
```
```{python 製作其他必修成績表現}
#定義其他
df252 = df[(df['開課系所'] != '軍訓（必選修）') &(df['名稱'] != '體育') & (df['科目名稱'] !='大一國文：經典閱讀與詮釋') &(df['科目名稱'] !='國文：經典閱讀與詮釋') & (df['科目名稱'] !='大學英文：英語聽講練習')  & (df['科目名稱'] !='大學英文') & (df['科目名稱'] !='英語聽講練習') & (df['科目名稱'] !='英文') & (df['科目名稱'] !='歷史') ]
df252 = df252[(df252['必選修類別（必／選／通）']=='必')]
df252 = df252[df252['是否為專業必修'] != 1]
#成績
df25_1 = df252.groupby(['學號','年級'])['學期成績'].sum().reset_index(name='學期成績加總')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積成績
df23 = df.groupby(['學號','年級'])['學期成績加總'].mean().reset_index()
df23['累積成績加總'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum().shift())
df23['累積成績加總pic'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積成績加總','累積成績加總pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#科目
df25_1 = df252.groupby(['學號','年級'])['科目名稱'].count().reset_index(name='學期科目數')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
##累積科目
df23 = df.groupby(['學號','年級'])['學期科目數'].mean().reset_index()
df23['累積科目數'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum().shift())
df23['累積科目數pic'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積科目數','累積科目數pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#累積平均
df['累積平均成績'] = df['累積成績加總']/df['累積科目數']
df['累積平均成績pic'] = df['累積成績加總pic']/df['累積科目數pic']
#pr比較
df = df.fillna(0)
df = df.assign(累積其他排名=df.groupby(['系別','年級','入學年'])['累積平均成績'].rank(pct=True).mul(100))
df = df.assign(累積其他排名pic=df.groupby(['系別','年級','入學年'])['累積平均成績pic'].rank(pct=True).mul(100))
#丟棄多餘變數
df=df.drop(['累積科目數','累積科目數pic','學期成績加總','學期科目數','累積平均成績','累積平均成績pic','累積成績加總','累積成績加總pic'],axis=1)
```
```{python 製作選修成績表現}
#定義選修
df253=df[df['必選修類別（必／選／通）'] == '選']
#成績
df25_1 = df253.groupby(['學號','年級'])['學期成績'].sum().reset_index(name='學期成績加總')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積成績
df23 = df.groupby(['學號','年級'])['學期成績加總'].mean().reset_index()
df23['累積成績加總'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum().shift())
df23['累積成績加總pic'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積成績加總','累積成績加總pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#科目
df25_1 = df253.groupby(['學號','年級'])['科目名稱'].count().reset_index(name='學期科目數')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積科目
df23 = df.groupby(['學號','年級'])['學期科目數'].mean().reset_index()
df23['累積科目數'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum().shift())
df23['累積科目數pic'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積科目數','累積科目數pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#累積平均
df['累積平均成績'] = df['累積成績加總']/df['累積科目數']
df['累積平均成績pic'] = df['累積成績加總pic']/df['累積科目數pic']
#pr比較
df = df.fillna(0)
df = df.assign(累積選修排名=df.groupby(['系別','年級','入學年'])['累積平均成績'].rank(pct=True).mul(100))
df = df.assign(累積選修排名pic=df.groupby(['系別','年級','入學年'])['累積平均成績pic'].rank(pct=True).mul(100))
#丟棄多餘變數
df=df.drop(['累積科目數','累積科目數pic','學期成績加總','學期科目數','累積平均成績','累積平均成績pic','累積成績加總','累積成績加總pic'],axis=1)
```
```{python 製作通識成績表現}
#定義通識
df254=df[df['必選修類別（必／選／通）'] == '通']
#成績
df25_1 = df254.groupby(['學號','年級'])['學期成績'].sum().reset_index(name='學期成績加總')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積成績
df23 = df.groupby(['學號','年級'])['學期成績加總'].mean().reset_index()
df23['累積成績加總'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum().shift())
df23['累積成績加總pic'] = df23.groupby(['學號'])['學期成績加總'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積成績加總','累積成績加總pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#科目
df25_1 = df254.groupby(['學號','年級'])['科目名稱'].count().reset_index(name='學期科目數')
df = pd.merge(df,df25_1,on=['學號','年級'],how='outer')
df = df.fillna(0)
##累積科目
df23 = df.groupby(['學號','年級'])['學期科目數'].mean().reset_index()
df23['累積科目數'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum().shift())
df23['累積科目數pic'] = df23.groupby(['學號'])['學期科目數'].apply(lambda x: x.cumsum())
df23 = df23.fillna(0)
df23=df23[['學號','年級','累積科目數','累積科目數pic']]
df = pd.merge(df,df23,on=['學號','年級'],how='outer')
#累積平均
df['累積平均成績'] = df['累積成績加總']/df['累積科目數']
df['累積平均成績pic'] = df['累積成績加總pic']/df['累積科目數pic']
#pr比較
df = df.fillna(0)
df = df.assign(累積通識排名=df.groupby(['系別','年級','入學年'])['累積平均成績'].rank(pct=True).mul(100))
df = df.assign(累積通識排名pic=df.groupby(['系別','年級','入學年'])['累積平均成績pic'].rank(pct=True).mul(100))
#丟棄多餘變數
df=df.drop(['累積科目數','累積科目數pic','學期成績加總','學期科目數','累積平均成績','累積平均成績pic','累積成績加總','累積成績加總pic'],axis=1)
```
```{python}
#專業必
dfpic8_1 = df.copy()
dfpic8_1['年級'] = dfpic8_1['系級'].str[-1]+ dfpic8_1['學期'].astype(str)
dfpic8_1=dfpic8_1[dfpic8_1['年級'] != '11']
dfpic8_1 = dfpic8_1.groupby(['學號','學年','學期','年級','是否被二一'])['累積專業排名pic'].mean().reset_index(name='pr')
dfpic8_1['是否被二一'] = dfpic8_1['是否被二一'].astype(str)
#共同必
dfpic8_2 = df.copy()
dfpic8_2['年級'] = dfpic8_2['系級'].str[-1]+ dfpic8_2['學期'].astype(str)
dfpic8_2=dfpic8_2[dfpic8_2['年級'] != '11']
dfpic8_2 = dfpic8_2.groupby(['學號','學年','學期','年級','是否被二一'])['累積共同排名pic'].mean().reset_index(name='pr')
dfpic8_2['是否被二一'] = dfpic8_2['是否被二一'].astype(str)
#其他必
dfpic8_3 = df.copy()
dfpic8_3['年級'] = dfpic8_3['系級'].str[-1]+ dfpic8_3['學期'].astype(str)
dfpic8_3=dfpic8_3[dfpic8_3['年級'] != '11']
dfpic8_3 = dfpic8_3.groupby(['學號','學年','學期','年級','是否被二一'])['累積其他排名pic'].mean().reset_index(name='pr')
dfpic8_3['是否被二一'] = dfpic8_3['是否被二一'].astype(str)
#選
dfpic8_4 = df.copy()
dfpic8_4['年級'] = dfpic8_4['系級'].str[-1]+ dfpic8_4['學期'].astype(str)
dfpic8_4=dfpic8_4[dfpic8_4['年級'] != '11']
dfpic8_4 = dfpic8_4.groupby(['學號','學年','學期','年級','是否被二一'])['累積選修排名pic'].mean().reset_index(name='pr')
dfpic8_4['是否被二一'] = dfpic8_4['是否被二一'].astype(str)
#通
dfpic8_5 = df.copy()
dfpic8_5['年級'] = dfpic8_5['系級'].str[-1]+ dfpic8_5['學期'].astype(str)
dfpic8_5=dfpic8_5[dfpic8_5['年級'] != '11']
dfpic8_5 = dfpic8_5.groupby(['學號','學年','學期','年級','是否被二一'])['累積通識排名pic'].mean().reset_index(name='pr')
dfpic8_5['是否被二一'] = dfpic8_5['是否被二一'].astype(str)
```

```{python 累計群聚指標特徵1}
#同班定義為同系級且同學年學期修課者。
#同班不用入學年與系別定義的原因為，解決較晚入學者若同學們都畢業後會造成沒有班標準差的問題。
#創造作法為在同學期時同系級年級同學有多少人一起同時修該門課。
df26 = df.groupby(['ClassId','系別','入學年']).size().reset_index(name = '該班幾人修')
df = pd.merge(df,df26,on =['ClassId','系別','入學年'] ,how ='outer')
#扣掉自己
df['該班幾人修'] = df['該班幾人修'] - 1
df26_1 = df.groupby(['學號','學年','學期'])['該班幾人修'].sum().reset_index(name = '群聚指標')
df26_1['累積群聚指標'] = df26_1.groupby(['學號'])['群聚指標'].apply(lambda x: x.cumsum())
#df26_1 = df26_1.drop(['學期中遇到多少同班的人'],axis=1)
df = pd.merge(df,df26_1,on = ['學號','學年','學期'],how ='outer')
```
```{python 製圖 , eval = FALSE}
df27 = df.groupby(['學號','系別','入學年'])['累積群聚指標'].max().reset_index()
df27 = df27.groupby(['系別','入學年'])['累積群聚指標'].median().reset_index(name = '在校最後一年累積群聚中位數')
#df27['累計群聚指標中位數'] = df27['累計群聚指標中位數'].astype(int)
```
```{python 累計群聚指標2}
#各學期班上的群聚指標平均
dfmean29 = df.groupby(['學號','系級','學年','學期'])['群聚指標'].mean().reset_index(name = '個人群聚指標')
dfmean29 = dfmean29.groupby(['系級','學年','學期'])['個人群聚指標'].mean().reset_index(name = '班群聚平均數')
#各學期班上的外系修課標準差
dfstd29 = df.groupby(['學號','系級','學年','學期'])['群聚指標'].mean().reset_index(name = '個人群聚指標')
dfstd29 = dfstd29.groupby(['系級','學年','學期'])['個人群聚指標'].std().reset_index(name = '班群聚標準差')
df29 = pd.merge(dfmean29,dfstd29,on=['系級','學年','學期'],how='outer')
dfdd = pd.merge(df,df29,on=['系級','學年','學期'],how='outer')
dfdd['標準化群聚指標'] = (dfdd['群聚指標'] - dfdd['班群聚平均數']) / dfdd['班群聚標準差']
dfdd['標準化群聚指標']=dfdd['標準化群聚指標'].fillna(0)
df30=dfdd.groupby(['學號','學年','學期'])['標準化群聚指標'].mean().reset_index()
#df30['累積標準化群聚指標'] = df30.groupby(['學號'])['標準化群聚指標'].apply(lambda x: x.cumsum().shift())
df30['累積標準化群聚指標'] = df30.groupby(['學號'])['標準化群聚指標'].apply(lambda x: x.cumsum())
df30 =df30.fillna(0)
#df30 = df30.drop(['標準化群聚指標'],axis=1)
df = pd.merge(df,df30,on=['學號','學年','學期'],how='outer')
```
```{python}
dfpic9 = df.copy()
dfpic9['年級'] = dfpic9['系級'].str[-1] + dfpic9['學期'].astype(str)
dfpic9 = dfpic9[dfpic9['年級'] != '11']
dfpic9 = dfpic9.groupby(['學號','學年','學期','年級','是否被二一'])['累積標準化群聚指標'].mean().reset_index(name='累積標準化群聚指標')
dfpic9['是否被二一'] = dfpic9['是否被二一'].astype(str)
```
```{python 欲預測學期專業必修衡量特徵}
a=[]
dfname = df.groupby(['系別']).size().reset_index()
for x in dfname['系別']:
  a.append(x)
#利用迴圈建造各系各年級必修課的dataframe，並加入list中
b=[]
for i in range(len(a)):
  dfchg = (df[(df['系別'] == a[i]) & (df['是否為專業必修'] == 1)])
  dfchg = dfchg.groupby(['科目名稱','入學年']).size().reset_index(name=a[i])
  dfchg = dfchg.groupby(['入學年'])['科目名稱'].size().reset_index(name=a[i])
  b.append(dfchg)
#將各個dataframe從list中拿出並合併
b1=pd.merge(b[0],b[1])
count = 0
for i in range(len(b)):
    b1=pd.merge(b1,b[i],how = 'outer')
b1 = (b1.T)
b1.drop(b1.index[0], inplace=True)
b1.fillna(0,inplace=True)
b1.columns = ['100','101','102','103','104','105','106']
b1=b1.drop(['104','105','106'],axis=1)

b2=b1.reset_index()
b2=pd.melt(b2, id_vars=["index"], 
                  var_name="入學年", value_name="系必修數")
b2.columns=['系別','入學年','系必修數']
df=pd.merge(df,b2,on = ['系別','入學年'],how='outer')
df['該學期專業與其他必修修課比例'] = (df['當學期專業必修修課數'] + df['當學期其他必修修課數'])/df['系必修數']
```
```{python 欲預測學期共同必修衡量特徵}
#體育四堂+英講一堂+英文兩堂+國文兩堂+歷史兩堂＝11
df['該學期共同必修修課比例'] = df['當學期共同必修修課數']/11
```
```{python 欲預測學期選修衡量特徵}
#計算每人選修課數、 各班中位數
dfclass2 = df[(df['必選修類別（必／選／通）'] == '選') & (df['不及格'] != 1)]
dfclass2 = dfclass2.groupby(['系別','入學年','學號']).size().reset_index(name = '個人選修數')
dfclass2 = dfclass2.groupby(['系別','入學年'])['個人選修數'].median().reset_index(name = '班選修中位數')
df = pd.merge(df,dfclass2,on=['系別','入學年'],how='outer')

df['該學期選修修課比例'] = df['當學期選修修課數']/df['班選修中位數']
```
```{python 欲預測學期通識衡量特徵}
df['該學期通識修課比例'] = df['當學期通識修課數']/12
```
```{python}
dfpic11 = df.copy()
dfpic11['年級'] = dfpic11['系級'].str[-1] + dfpic11['學期'].astype(str)
dfpic11 = dfpic11[dfpic11['年級'] != '11']
dfpic11 = dfpic11.groupby(['學號','學年','學期','年級','是否被二一'])['該學期專業與其他必修修課比例'].mean().reset_index(name='該學期專業與其他必修修課比例')
dfpic11['是否被二一'] = dfpic11['是否被二一'].astype(str)

dfpic12 = df.copy()
dfpic12['年級'] = dfpic12['系級'].str[-1] + dfpic12['學期'].astype(str)
dfpic12 = dfpic12[dfpic12['年級'] != '11']
dfpic12 = dfpic12.groupby(['學號','學年','學期','年級','是否被二一'])['該學期選修修課比例'].mean().reset_index(name='該學期選修修課比例')
dfpic12['是否被二一'] = dfpic12['是否被二一'].astype(str)

dfpic13 = df.copy()
dfpic13['年級'] = dfpic13['系級'].str[-1] + dfpic13['學期'].astype(str)
dfpic13 = dfpic13[dfpic13['年級'] != '11']
dfpic13 = dfpic13.groupby(['學號','學年','學期','年級','是否被二一'])['該學期通識修課比例'].mean().reset_index(name='該學期通識修課比例')
dfpic13['是否被二一'] = dfpic13['是否被二一'].astype(str)

dfpic14 = df.copy()
dfpic14['年級'] = dfpic14['系級'].str[-1] + dfpic14['學期'].astype(str)
dfpic14 = dfpic14[dfpic14['年級'] != '11']
dfpic14 = dfpic14.groupby(['學號','學年','學期','年級','是否被二一'])['該學期共同必修修課比例'].mean().reset_index(name='該學期共同必修修課比例')
dfpic14['是否被二一'] = dfpic14['是否被二一'].astype(str)

```
```{python}
#四捨五入
def oo(x) :
  x = x*1000
  if x % 10 >=5:
    return (int(x/10) +1)/100
  else:
    return int(x/10)/100
df['年級'] = df['系級'].str[-1].astype(str) + df['學期'].astype(str)
dfpic9 = df.copy()
dfpic9=dfpic9.drop(['Unnamed: 0', 'index', '系級', '姓名', '學期成績', '科目代碼', '科目名稱', '學分數','開課系所', '修課人數', '班別', '授課老師','必選修類別（必／選／通）','授課語言','上課時間及教室','系別','ClassId','mainstudent','mainnumber','mainQ2/3','mainQ1/2', 'main1/2college','該班人數','名稱', '不及格','實拿學分'],axis=1)
dfpic9_1=dfpic9.drop_duplicates()
dfpic9_1 = dfpic9_1[['學號','學年','學期','是否被二一','累積標準化群聚指標','累積通識被當比','累積選修被當比','累積專業必修被當比','累積共同必修被當比','累積其他必修被當比','該學期選修修課比例','累積專業排名','累積其他排名','累積共同排名','累積選修排名','累積通識排名','累積二一']]
dfpic9_1 = dfpic9_1.groupby(['學號','學年','學期']).mean().reset_index()
```
```{r}
py$dfpic9_1 %>% group_by(學號) %>% slice(-1) -> dfpn
dfpn$學號 <-as.character((dfpn$學號))
dfpn %>% group_by(學號) %>% mutate(學期 = row_number()+1) ->dfpn
```
```{python}
dfpn = r.dfpn.copy()
#dfpn = dfpn.drop(['學號','學年'],axis=1)
```

```{python}
#pic2 GPApic沒有
dfpic99 = df[['是否被二一','累積標準化群聚指標','累積通識被當比','累積選修被當比','累積專業必修被當比','累積共同必修被當比','累積其他必修被當比','該學期選修修課比例','累積專業排名','累積其他排名','累積共同排名','累積選修排名','累積通識排名','累積二一']]
#dfpic99.rename(columns={'累計標準化群聚指標pic':'累計標準化群聚指標','累計外系修課指標pic':'累計外系修課指標','GPApic':'GPA'}, inplace=True)
```
```{python}
#weight 10
#dfpn1 = dfpn.copy()
#dfpn1['是否被二一'] = np.where(dfpn1['是否被二一'] =='1','yes','no')
#dfpn1['weight'] = np.where(dfpn1['是否被二一']=='yes',10,1)

#weight資料比
dfpn2 = dfpn.copy()
dfpn2['是否被二一'] = np.where(dfpn2['是否被二一'] ==1,'yes','no')
dfpn2['weight'] = np.where(dfpn2['是否被二一']=='yes',35319/398,1)

```
```{r}
#weight 10
#rdf1 <- py$dfpn
#rdf1$是否被二一 <- as.factor(rdf1$是否被二一)
#weight資料比
rdf2 <- py$dfpn2
rdf2$是否被二一 <- as.factor(rdf2$是否被二一)
```
```{r}
#no weight
#set.seed(123)
#trainIndices = createDataPartition(rdf2$是否被二一, p=.8, list=F)
#train1_1 <- rdf2[trainIndices,] %>% dplyr::select(-weight,-學號,-學年)
#test1_1 <- rdf2[-trainIndices,] %>% dplyr::select(-weight,-學號,-學年)
#good_observed1_1 =test1_1$是否被二一
#weight資料比
#train2_1 <- rdf2[trainIndices,] %>%  dplyr::select(-weight,-學號,-學年)
#train2_2 <- rdf2[trainIndices,]
#test2_1 <- rdf2[-trainIndices,] %>%  dplyr::select(-weight,-學號,-學年)
#good_observed2_1 =test2_1$是否被二一
#smote人工建造資料https://zhuanlan.zhihu.com/p/24826792

nID <- length(unique(rdf2$學號))
p = 0.8
set.seed(123)
inTrainID <- sample(unique(rdf2$學號), round(nID * p), replace=FALSE)
train3_1 <- rdf2[rdf2$學號 %in% inTrainID, ] %>%  dplyr::select(-weight,-學號,-學年)
test3_1 <- rdf2[!rdf2$學號 %in% inTrainID, ] %>%  dplyr::select(-weight,-學號,-學年)
testid <- rdf2[!rdf2$學號 %in% inTrainID, ] %>%  dplyr::select(-weight)
good_observed3_1 =test3_1$是否被二一
mysmote <- SMOTE(是否被二一~., train3_1,perc.over =100,perc.under = 200,k=5)
##table(mysmote $是否被二一)
#過採樣、欠採樣、雙採樣https://blog.csdn.net/qq_34139222/article/details/57461398
#train4_1 <- rdf2[trainIndices,] %>%  dplyr::select(-weight,-學號,-學年)
#test4_1 <- rdf2[-trainIndices,] %>%  dplyr::select(-weight,-學號,-學年)
#good_observed4_1 =test4_1$是否被二一
#myover <- ovun.sample(是否被二一~., data = train4_1, method = "over",N = 56512)$data#28256*2
#myunder <- ovun.sample(是否被二一~., data = train4_1, method = "under", N = 638, seed = 2)$data#319*2
#myboth <- ovun.sample(是否被二一~., data = train4_1, method = "both", p=0.5, N=28575, seed = 1)$data#兩者加起來的樣本數
ctrl <- trainControl(method="cv", 
                     summaryFunction=twoClassSummary, 
                     classProbs=T,
                     savePredictions = T,
                     number = 10)
```
```{r,warning=FALSE,message=FALSE}
#results1 = train(是否被二一~., 
   #                  data=train1_1, 
  #                   trControl = ctrl,
   #                  method='glm',
    #                 family=binomial(),
    #                 metric = "ROC")

#results2 = train(是否被二一~., 
   #                  data=train2_1, 
   #                  trControl = ctrl,
   #                  method='glm',
   #                  family=binomial(),
   #                  weights = train2_2$weight,
   #                  metric = "ROC")

results3 = train(是否被二一~., 
                     data=mysmote, 
                     trControl = ctrl,
                     method='glm',
                     metric = "ROC",
                     family=binomial())
summary(results3)

resultslog = train(是否被二一~累積專業排名, 
                     data=mysmote, 
                     trControl = ctrl,
                     method='glm',
                     metric = "ROC",
                     family=binomial())

#results4 = train(是否被二一~., 
               #      data=myover, 
               #      trControl = ctrl,
               #      method='glm',
               #     family=binomial(),
                #     metric = "ROC")
#results5 = train(是否被二一~., 
                #     data=myunder, 
                #     trControl = ctrl,
                #     method='glm',
                #     family=binomial(),
                #     metric = "ROC")
#results6 = train(是否被二一~., 
                   #  data=myboth, 
                   #  trControl = ctrl,
                   #  method='glm',
                   #  family=binomial(),
                   #  metric = "ROC")

rf_opts = data.frame(mtry=c(2:18))

resultsrf = train(是否被二一~., 
                     data=mysmote, 
                     trControl = ctrl,
                     method='rf',
                     tuneGrid = rf_opts,
                     metric = "ROC")

resultssvm = train(是否被二一~., 
                     data=mysmote, 
                     trControl = ctrl,
                     method='svmRadial',
                     metric = "ROC")

resultsnnet = train(是否被二一~., 
                     data=mysmote, 
                     trControl = ctrl,
                     method='nnet',
                     metric = "ROC")

```
```{r}
#preds1 = predict(results1, test1_1)
#preds2 = predict(results2, test2_1)
preds3 = predict(results3, test3_1)
predslog = predict(resultslog, test3_1)
#preds4 = predict(results4, test3_1)
#preds5 = predict(results5, test3_1)
#preds6 = predict(results6, test3_1)
predsrf = predict(resultsrf,test3_1)
predsvm = predict(resultssvm,test3_1)
prednnet = predict(resultsnnet,test3_1)
#c1<- confusionMatrix(table(preds1, good_observed1_1),positive = 'yes')
#c2 <- confusionMatrix(table(preds2, good_observed2_1),positive = 'yes')
c3 <- confusionMatrix(table(preds3, good_observed3_1),positive = 'yes')
clog <- confusionMatrix(table(predslog, good_observed3_1),positive = 'yes')
#c4 <- confusionMatrix(table(preds4, good_observed3_1),positive = 'yes')
#c5 <- confusionMatrix(table(preds5, good_observed3_1),positive = 'yes')
#c6 <- confusionMatrix(table(preds6, good_observed3_1),positive = 'yes')
ctree <- confusionMatrix(table(predsrf, good_observed3_1),positive = 'yes')
csvm <- confusionMatrix(table(predsvm, good_observed3_1),positive = 'yes')
cnnet <- confusionMatrix(table(prednnet, good_observed3_1),positive = 'yes')

#log <- glm(formula = 是否被二一 ~. ,data=rdf2, family=binomial(link="logit") )
#aa <- predict(log,rdf2, type = "response")
#報告用
application = cbind(testid,predsrf)

application4100=application %>% filter(學號 == 	410080053)
```
```{r}
# make prediction on train data (no need to specify newclass= ) # NOT very useful
pred <- predict(results3, type = "raw")
caret::confusionMatrix(pred, mysmote$是否被二一)

confusionMatrix(resultsrf$pred$pred, resultsrf$pred$obs)
confusionMatrix(resultssvm$pred$pred, resultssvm$pred$obs)
confusionMatrix(results3$pred$pred, results3$pred$obs)
confusionMatrix(resultsnnet$pred$pred, resultsnnet$pred$obs)


length(resultsrf$pred[order(resultsrf$pred$rowIndex),2])
length(results3$pred[order(results3$pred$rowIndex),2])
length(resultssvm$pred[order(resultssvm$pred$rowIndex),2])
length(resultsnnet$pred[order(resultsnnet$pred$rowIndex),2])
length(mysmote$是否被二一)
confusionMatrix(resultsrf$pred[order(resultsrf$pred$rowIndex),2], mysmote$是否被二一)
```

```{r}
#preds3 = predict(results3)
#c3 <- confusionMatrix(preds3, mysmote$是否被二一)


#predsrf = predict(resultsrf)
#ctree2 <- confusionMatrix(predsrf , mysmote$是否被二一)

#resultssvm$pred %>% filter(resultssvm$pred$C ==1) -> abc
#abc %>% filter(abc$sigma <= 0.07043302) ->def
#confusionMatrix(def$pred , def$obs)

#predsvm = predict(resultssvm)
#csvm <- confusionMatrix(predsvm, mysmote$是否被二一)

#predsnnet = predict(resultsnnet)
#cnnet <- confusionMatrix(predsnnet, mysmote$是否被二一)
```


# 摘要

# 緒論

## 研究背景

現今國內外大學普遍存有督促學生學習狀況的機制，主要是以學生的在校成績作為其衡量標準，校方對於未達到標準的學生會進行懲罰的措施，旨在希望學生不要荒廢課業。
大學退學可分為「自退」與「勒令退學」，自退為學生主動於校方申請退學，而勒令退學則屬校方強迫退學，按學校規定勒令退學將分為「非因成績退學」，以及「因成績退學」，早期之因成績退學制度普遍為「二一退學」，即實拿學分不及學期總學分二分之一便退學，然而教育部開放大學自主之後，陸續有許多學校對於退學標準做出調整，退學制度較為主流的為下列三者；較為嚴格的「三二退學」即實拿學分不及學期總學分三分之二便退學，較為寬鬆的「連續雙二一退學」即在校期間連續被二一兩次才會被退學，最後一項為「雙二一退學」，亦即在校期間累積被二一兩次才會退學，[1]交通大學註冊組組長彭淑嬌指出，十幾年前教育部開放給大學自主時，曾有一波廢除二一制度的聲浪，當時交大也因此廢除「單二一退學制度」，但後遺症很明顯，學生學習動力大幅減弱，校方只好又改採雙二一制度，雖近期陸續有學校開始廢除因成績退學制度，但目前大多數之大學仍保有著因成績退學機制；[2]研究也指出二一制度仍然對於學生可以有效達到嚇阻的功用，學生在被二一後的不及格學分比例在往後的學期會有所改善，故學生是否被二一仍是一個很好的學習成效指標。

## 研究動機與文獻回顧

### 研究動機

台灣社面臨少子化的趨勢，造成各級教育機構入學人數普遍下滑，教育部因應此趨勢於民國102年推動大學整併計畫，針對一縣市有兩所以上的公立大學且單一學校學生人數在一萬人以下的公立大學推動整併；私立大學學生人數於兩千人以內，則推動退場機制。[3]為維持學校的規模，各大院校愈來愈重視學生的退學問題；若能夠於早期預測出學生退學，以減少退學的比例，對於學生與學校將會是雙贏。
鑑於校方於學期中才能發送期中預警，本文希望能夠透過模型在學期開始前便有效的預測該學期是否會被二一，於學期初期便能給予老師或是周遭同學訊號，發揮同儕之間的影響力共同關懷學習上遭遇困難的學生；鄭媛文（2013）研究指出教師對於學生學習成效之認知、情意及技能部分有顯著的影響，同儕教導學習策略對學生的「學習成就」、「情意態度」均有正向的影響，可見教師與同儕的影響在學習過程中扮演了息息相關的角色，透過儘早預測出需要幫助的學生，校方可以從教師與同儕方面擬出一些補救政策幫助學生。
對於學生被發送期中預警，陳家琪（2017）針對台北市立大學103和104學年度大學部的學生運用過往修課狀況進行了研究，研究顯示大一學生以及大二學生被期中預警的比例是最高的，反應了學生對於大學的生活可能存有一定程度上的不適應，且各學學生收到期中預警的原因也不盡相同，如體育學院的學生主要被預警的原因為出缺席率而理學院的學生多為成績表現上的問題，李勁昇（2017）也針對同間學校進行了修課習慣（學分數、時間、星期）進行分析，探討其學習成效，分別發現修課總學分數與學期平均成績大多呈負相關；下午修課平均成績皆高於上午；跨星期上課的科目（每週上課時間分二天以上），學生的平均成績顯著最低，學生成績表現不好不僅學校會影響學校的學生人數，對於學生心理狀況與人際狀況也會有所影響，根據李易倫（2015）研究指出學業成績的自我覺察與人際關係具有正向的關聯性，以及大學生的學業成績與課堂焦慮具有負向關聯，若能早點給予學生成績上的幫助，除提升成績外也可以降低學生的心裡壓力。

### 機器學習的應用

目前對於教育的資料探勘研究比起金融、醫療領域來說相對較少，將資料探勘運用於教育領域之中稱為教育資料探勘，教育資料探勘主要可以透過萃取影響學生學習的因素，加強我們對於學習以及教育的理解，Abu-Oda and El-Halees（2015）表示目前高等教育遭遇許多問題，導致教育機構逐步遠離了實現重視教育質量的目標，Baepler and Murdoch（2010）進一步指出大多數的原因來自於校方與學生之間的資訊落差；校方無法獲得足夠多的信息來為學生提供合適的教育，若校方能夠透過數據探勘預測學生的類型，將可以使高等教育機構以個別化的方式做出更好的決策，擬定教育時可以為學生採取較為客製化的計劃，使得教育機構能夠更有效地分配資源和人力。

Abu-Oda,El-Halees（2015）也運用了ALAQSA 大學計算機科學系的成績單與高中成績來預測輟學的學生，希望透過預測結果針對教育有較好的理解；在研究中針對預測使用兩種演算法；分別為決策樹模型以及Naive Bayes模型，分別得出98.14%與96.86%的準確度，達到良好的預測結果，而使用較多演算法預測輟學相關的文獻有Kotsiantis,Pierrakeas and Pintelas（2004）對於與學生的學習成效進行了相關的預測，將機器學習應用於Hellenic Open University遠程教育預測中；預測出哪一類型學生輟學的可能性最高；使得遠端導師可以採取預防措施減少學生的輟學率，（Schaffer 1994）提到由於每個機器學習的演算法都各自擁有一些偏差值，也就代表說某個演算法在A領域中表現良好，很有可能在B領域表現是不佳的，故必須對各個不同的演算法做出比較。

在Kotsiantis,Pierrakeas and Pintelas（2004）研究中分別提出了六種演算法預測輟學，其中包括；決策樹、羅吉斯回歸、Naive Bayes、 K-nearest neighbor、人工神經網路、支持向量機，其中Naive Bayes 演算法表現最佳，其平均預測準確率為70.51%，Cortez and Silva（2013）也使用了隨機森林、支持向量機、人工神經網路以及決策樹對中學生的數學科目以及葡萄牙語科目進行了成績的預測，研究顯示在已知過去成績下此預測可以達到很高的準確率，這與Kotsiantis（2004）中的結論相互呼應：學生的現今成就表現受過去的成績表現影響很大，儘管如此預測力較高的模型通常也包含了以下的其他因素，如：學校相關（例如：缺勤人數、選擇學校的理由、額外的教育），人口統計學（例如：學生的年齡、父母的工作和教育）和社交（例如：與朋友外出）變數仍存在很大的影響。

另外Dekker,Pechenizkiy and Vleeshouwers（2009）於研究中提到輟學學生中有一類型特別的學生，稱之為風險類學生，此類型的學生特點在於，有高機率是不會被退學的學生，卻因種種原因被退學；也就是說校方必須提供更多的資源在他們身上，他們才能免於被退學，研究中透過高中以及大學的成績資料建構決策樹模型以提前預測出此類型的學生，準確度高達75%至80%之間，這項研究將有助於學生與老師共同改善學生的成績表現，使得校方可以降低學生的輟學比例，綜觀上述案例不難發現，決策樹於教育資料探勘中非常受歡迎，Baradwaj and Pal（2012）提出因為它們產生的分類規則比起其他的演算法分類更為直覺，在他所製作的文獻中也在決策樹運用於分類學生的成績表現中得到不錯的預測效果，依變數重要性提取出的幾個重要變數可以有效的預測學生在期末考的表現，有助於提早的識別需要幫助的學生，以利老師提供適當的諮詢與建議，綜合上述文獻回顧中，本文將使用上述所提及較常使用的演算法來進行二元分類的預測，包括羅吉斯回歸、人工神經網路、支持向量機以及隨機森林。

# 資料說明與觀察

## 資料簡介

本文所使用原始資料為大學部100至106學年成績單資料，含有55萬353筆成績資料，資料來源為國立臺北大學校務研究辦公室，成績單中含有少許100年以前入學之學生不完整資料，成績單欄位有以下幾者：系級、學號、姓名、學期成績、科目代碼、科目名稱、學分數、開課系所、修課人數、班別、授課老師、學年、學期、必選修類別（必／選／通）、授課語言、上課時間及教室。

## 資料處理

本文為使資料能夠有更完整的特徵以及期數預測二一，將排除修課未滿八學期者，僅剩3萬5千717筆成績資料，專注於具有完整修完八學期之同學的二一預測，由於成績單中所含有的資訊量過於龐大與雜亂，無法直接納入模型進行預測，本節我們將對資料的特徵進行改建，依序觀察與介紹。

### 預測變數二一狀況觀察

#### 二一頻率觀察

觀察校內被二一的學生狀況為何，圖1中顯示了100學年度起至103學年入學年擁有完整八學期的學生，共有4941位學生，被二一的學生人數有364筆佔學生人數的7%，兩類預測值資料筆數相差甚大，為典型的不平衡資料，其中被二一壹次的人數最為多筆，共有295筆，被二一兩次的人數有46筆；三次以上的人數則有23筆，本校為雙二一制度；依據校內規定一般在校生若被二一次數兩次後便會強制退學，若資料中出現學生被二一次數超過兩次則代表該位學生為僑生或是身心障礙學生，由圖1可知出大部分的學生在被二一壹次後，會設法減少自己再次被二一的可能；二一制度對學生具有一定的警惕作用。

#### 二一時間性觀察

考慮學生是否會因為不同入學年此類的時間性因素，導致不同入學年學生被二一的比例有所差異，圖2顯示了入學年度與被二一的關係，可知各入學年在二一比例上相對隱定，皆約佔一成，代表著入學年是學生被二一
的因素的機會不高；此反應了每個入學年中皆有一部分的學生對於大學的教育出現了不適應的狀況。

```{r 1, results="asis" }
py$df4 %>% DT::datatable()
ggplot(py$df4 , aes(x= 二一次數,y=人數)) + geom_bar(stat="identity") + coord_flip()+
  labs(x='二一次數',y = "人數",size=10)
#ggsave('pic1.png',width=1,height=1)
```

```{r 2, results="asis" }
ggplot(py$dfpic2_1, aes(x = 入學年, fill = 二一)) +  
  geom_bar(position = "fill") +
  labs(x='入學年',y = "比例",size=10) +scale_y_continuous(breaks=seq(0,1,0.1))+ scale_fill_manual(name='二一',values=c("#40E0D0", "#FF7F50"))
#ggsave('pic2.png')
```

因原始成績單的變數較為複雜，我們自原始成績單中各欄位改建為較為有用的特徵，以前幾期的特徵預測未來學期同學是否會被二一，本研究擬於每學期初去預測學期結束後，個別學生被二一的可能性，故預測特徵可分為預測學期以前的訊息以及預測學期初的訊息，下小節將分別介紹各類特徵。

### 預測學期以前的訊息

由二一觀察頻率小節中，可以清楚看到大部份學生於發生一次二一後下次再度發生的頻率不高；二一次數兩次以上相對一次來得少，在此想更深入探討了被二一的學生以往的累積二一狀況為何？以及於哪些年級是學生被二一最常發生的時間點？

#### 累積二一

圖3為被二一的學生中，累積至預測當期前的二一狀況，橫軸數字代表第幾學期，圖顯示，學生於一年級時發生被二一的狀況是最多的，其反映了被二一的學生中，有很大的比例對於初上大學的教學與生活是很不適應的，而被二一人數另一處高峰位於大四，在大四時被二一的學生分為兩種，第一種為，大四修課數較少而導致，修課數較少狀況下，若有幾門課被當便很容易造成被二一；為圖中橘色的部分，第二種可能為橘色以外的部分，這些學生都是曾經有被二一紀錄的學生，而到大四時又再度被二一；由此可知被二一過的學生大四時有很大的機率會延續之前的學習狀態導致大四再度被二一，通過初步的觀察，為了捕捉到這些大四而又再次被二一的人，我們將加入變數「累積二一」當作解釋變數，以預測同學未來是否會被二一。

```{r 3, results="asis" }
ggplot(py$dfpic3_1, aes(x = 年級,fill = 累積二一)) +  
  geom_bar()+
  labs(x='學期',y = "累積二一",size=10)+ scale_fill_discrete(name='累積二一次數')+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))+ scale_fill_manual(name='累積二一次數',values=c("#40E0D0", "#FF7F50","#DDAA00","#DDAA00","#DDAA00","#DDAA00","#DDAA00"))
#ggsave('pic3.png')
```

本節中指出了，有些學生的學習模式是會延續下去的，尤其在大四時，發生被二一的狀況最為嚴重，而學習模式的好壞可以以成績衡量為一個判斷標準，下小節將延續本節觀察以過往成績面向的表現探討學習模式良好與不適應的學生於未來二一的表現。

#### 累積被當比

在課程類型上，大類可分成「必修」、「選修」及「通識」，其中必修又可細分成專業必修、共同必修、其他必修三類。
其中專業必修指得是該生所屬學系的必修（註：由於全校學系眾多，各系必修科目又有可能調動，故在判定上是以該屆同學有超過一半以上修習之必修科目名稱，即定義為該生所屬學系之專業必修科目；舉例來說：100學年入學之經濟系學生有超過5成，其成績單上有出現標示為「必」修的「個體經濟學」成績，則「個體經濟學」會判定為此學年入學經濟系學生之專業必修。），其他必修為雙主修、輔修或是修習教育學程學生另外的必修課，共同必修為本校之共同必修，涵蓋體育、英文、英文聽講、歷史以及國文。

而在這五類課程我們去統計學生到前學期為止的適應狀況，所使用的適應狀況特徵為，學生至該學期為止在各類所修的總課程數目中被當掉的比例——此比例越高表示該學生在該類課程適應越不良。以此，我們建構了五個累積被當比例：累積專業必修被當比例、累積共同必修被當比例、累積其他必修被當比例、累積選修被當比例以及累積通識被當比例，採用比例定義的原因為，每人的修課數會受到系級的不同、個人是否雙主修、輔修、教育學程或是不同入學年所影響，為能夠排除立足點不同的情形，故採用比例制。

```{r}
p1 <- ggplot(py$dfpic4, aes(x=年級, y=累積專業必修被當比, fill=是否被二一)) + 
    geom_boxplot(outlier.shape = NA)+labs(x='學期',y = "累積專業必修被當比") + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50")) +theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r}
p1_1 <- ggplot(py$dfpic4_1, aes(x=年級, y=累積共同必修被當比, fill=是否被二一)) + 
    geom_boxplot(outlier.shape = NA)+labs(x='學期',y = "累積共同必修被當比",size=5)  + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r}
p1_2 <- ggplot(py$dfpic4_2, aes(x=年級, y=累積其他必修被當比, fill=是否被二一)) + 
    geom_boxplot(outlier.shape = NA)+labs(x='學期',y = "累積其他必修被當比",size=5)  + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r}
p2 <- ggplot(py$dfpic5, aes(x=年級, y=累積選修被當比, fill=是否被二一)) + geom_boxplot(outlier.shape = NA)+labs(x='學期',y = "累積選修被當比",size=10)  + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r}
p3 <- ggplot(py$dfpic6, aes(x=年級, y=累積通識被當比, fill=是否被二一)) + 
    geom_boxplot(outlier.shape = NA)+labs(x='學期',y = "累積通識被當比",size=10)  + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold")) + scale_x_discrete(labels = c(2,3,4,5,6,7,8)) 
```
```{r 4, results="asis" }
multiplot(p1,p1_1,p1_2,cols=1)
```

累積專業必修被當比可以看出一位學生在本系專業領域的修課狀況，由圖4可知於專業領域上，沒被二一的學生表現明顯比被二一者好，而也因專業領域上的知識通常較深所以會導致專業被當比無法像其他兩種類型的必修課一樣，被當比的第75百分位數為0，由此可知一位學生若在以往的專業科目上表現良好，那麼可以預期到，他在未來被二一的可能性是較低的。
於累積其他必修類別中，大一至大二時兩類學生的被當比第75百分位數皆為0，其主要原因為大部分學生在大學初期較不會申請如教育學程之類的外系專業課程，而在大三至大四時，此特徵可以捕捉到，學生於外系專業上的不適應會導致未來被二一可能性提高。
必修類裡最後一類為累積共同必修被當比，所捕捉的是同學對於學校共同科目被當的狀況，而全校共同科目必須顧及全校各系的學生程度，所以通常會是一門相對不容易被當的科目，若此類型的科目被當給出的訊號為學生對於大學生活的不適應，包括時間控管、等等非學習上的因素，圖4中清楚呈現，沒被二一類型的學生被當比第75百分位數皆為0，代表此類裡大部分的學生，對於大學生活適應程度不算太糟，而被二一類學生被當比的第75百分位數高於0，則顯示了，以往對於大學的不適應狀況越與未來被二一的擁有正向的關係。


```{r 5, results="asis" }
p3
```

通識課程旨在培養學生五大通識素養，包括人文、科學、民主、倫理與宏觀，從累積通識被當比可以判斷一位學生對於課外的素養培養的重視程度，從圖5顯示未來容易被二一的學生，對於以往的課外探索，相對於沒被二一的學生，較不重視，沒被二一類學生此比例與被二一類學生的中位數差異不大，主因為此類課程的難易度較低，通常同學於此類課程較不易被當，除此之外，通識科目也給了學生許多選課彈性，通常成績較差的學生會趨吉避凶，選擇較容易的通識課程。

```{r 6, results="asis" }
p2
```

選修課程為一門更深入於專業領域的學科；若學生對某於專業領域中感到興趣，便會選修相關的課程，加強自己不管是外系亦或是本系的專業知識，可以預期，若學生在專業必修中或是其他必修的學習狀況不佳，那有很大的機會其累積選修被當比也會較高，圖6中顯示了兩類學生於此特徵的表現，可以看到兩類學生的第75百分位數差異很大，選修課程也給了學生一部分的選課彈性，故若學生選修被當比很高，我們傾向相信學生於未來被二一有較高的可能性。

綜合上述分析可知，兩類學生在累積被當比變數群中的差異顯著，說明了它們是合理的預測二一特徵變數，了解修課狀況後，下小節將進一步從各類課程中討論成績所帶來的影響。

#### 成績表現

上節中討論了必修、選修課程以及通識課程的被當狀況與兩類學生之間的關係，並且知道到被二一類學生會在較有選課彈性的科目上趨吉避凶，故必須藉由觀察各類課程上的排名，才能了解修課上的真實狀況，觀察以往的成績排名對於未來是否被二一影響為何？
在此與上小節一樣針對不同的課程類別進行分別討論。成績計算方式如下：計算累積至前一期某類別（如：累積專業必修）的課程總成績，除以累積至前一期某類別（如：累積專業必修）的修課數，得出累積平均總成績，以總成績與同班的同學進行排名，同班的定義為，同系、同年級且同入學年；將成績的高低排名，映射至0到100區間，最高分數同學會在此排名指標中對應到100，最低分則為0。

```{r ,warning=FALSE,message=FALSE}
p1 <- ggplot(py$dfpic8_1, aes(x=年級, y=pr, fill=是否被二一)) + 
    geom_boxplot( outlier.shape = NA) + 
    labs(x='學期',y = "累積專業排名",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p2 <- ggplot(py$dfpic8_2, aes(x=年級, y=pr, fill=是否被二一)) + 
    geom_boxplot( outlier.shape = NA)+ 
    labs(x='學期',y = "累積共同排名",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p3 <- ggplot(py$dfpic8_3, aes(x=年級, y=pr, fill=是否被二一)) + 
    geom_boxplot( outlier.shape = NA)+ 
    labs(x='學期',y = "累積其他排名",size=10)  + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p4 <- ggplot(py$dfpic8_4, aes(x=年級, y=pr, fill=是否被二一)) + 
    labs(x='學期',y = "累積選修排名",size=10)+
    geom_boxplot( outlier.shape = NA)+ scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50")) +theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p5 <- ggplot(py$dfpic8_5, aes(x=年級, y=pr, fill=是否被二一)) + 
    geom_boxplot( outlier.shape = NA)+ 
    labs(x='學期',y = "累積通識排名",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r 7, results="asis" }
multiplot(p1, p2,p3 ,cols=1)
```

累積專業必修排名所代表的意義為，對於學生的專業知識學習狀況做排序，由圖7觀察，被二一的同學於以往的專業知識表現上低於沒被二一生許多；第75百分位數皆低於25%，而在大四下時，被二一類學生的累積專業必修排名中位數顯著高於前幾期，顯示部分被二一生在大四上時，有嘗試的想讓自己的專業知識提高，但由於學習上的力不從心，導致雖有提升但是至大四下時仍被二一的狀況。
累積共同必修排名，代表著學生在學適應狀況的排序，圖7顯示，被二一的學生於以往的在學適應狀況會低於沒被二一生與前小節相互呼應。
累積其他必修排名較為特別，修此類別課程的學生人數相對其他兩類較少，故可以發現圖7中，兩類型學生的排名中位數沒有比前幾類必修課程差異還大，不過還是可以看出二一生與非二一生之間存有差異。

```{r 8, results="asis" }
p5
```

圖8為累積通識排名，可以推估，被二一的學生類型通常為過往較不認真培養通識五大素養的學生，而發現此處中位數的差異比起累積通識被當比更為明顯，因為此類課程屬較不易當人的類型，且其選課彈性也比其他類型的科目都來得大，中位數的差異於被當比中是無法被觀察到的。

```{r 9,results="asis" }
p4
```

圖9為累積選修排名，兩類學生差異很大，為一很好的預測變數。

通識課程與共同必修課程這類型的課程，相對於其他課程較不會出現當人的狀況，而導致我們在累積被當比小節中，累積被當比例的中位數二一生與非二一生皆為0，而在本節成績衡量當中，經過排序可以進一步劃分出，學生的排名狀況，藉由排名狀況的差異可以補捉到兩類學生的差異性，故將此類成績衡量變數作為一預測變數是合適的。下小節進入預測學期當學期可以提供何種訊息，即站在學期初我們要預測一位學生，除了前幾期特徵外，還有哪些特徵是可以得到的。

### 預測學期當學期訊息

研究目的為預測當學期結束前預測該生二一狀況，所以學生當學期所排定的學業課程繁重度也是重要的訊息。

在學期尚未結束前我們能夠得知關於該學期特徵的資訊僅有該學期必修數、選修數、通識數此類修課狀況特徵，為了能夠有效衡量學生在該學期修課的繁重程度，衡量方式將依據不同類型課程而有所差異，此處必修課類中僅拆成兩小類；專業與其他必修以及共同必修，主因為其他必修類別課程通常為外系的專業必修課程，其帶來的繁重程度與專業必修是相同的，故在此節中，屬同類型課程。
專業與其他必修課程的衡量特徵是，以當學期修了多少專業必修課程與其他必修課程總和，除以學生於本系畢業時應修的專業必修課數，此特徵衡量的概念是，學生在當學期選的專業必修課數（包含本系與外系）佔了多少畢業時所需的必修課數，此值越高代表，當學期的專業必修課程（包含本系與外系）繁重度越高。
共同必修衡量特徵是以當學期共同必修修課數除以十一，其原因為校方規定畢業時必須修完上下學期共十一門共同必修課，分別為國文上下學期、英文上下學期、英文聽講一學期、歷史上下學期以及體育四學期。
通識類課程衡量方式是以當學期通識修課數除以十二，統一除以十二原因為，校方規定最低畢業門檻為修滿上下學期共十二門通識課。
選修類型課程的衡量較為特殊，因各系所要求的畢業學分不同、必修數也不同，所以算法為，以當學期選修修課數除以，該位學生班上同學在當學期，所選修之選修課數的中位數；以此中位數代替畢業時選修規定堂數的真實值。

```{r results='asis',warning=FALSE}
p1 <- ggplot(py$dfpic11, aes(x=年級, y=該學期專業與其他必修修課比例, fill=是否被二一))+ geom_boxplot( outlier.shape = NA) + ylim(0,1)+labs(x='學期',y = "該學期專業與其他必修修課比例",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p2 <- ggplot(py$dfpic12, aes(x=年級, y=該學期選修修課比例, fill=是否被二一))+ geom_boxplot( outlier.shape = NA) + ylim(0,1)+labs(x='學期',y = "該學期選修修課比例",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p3 <- ggplot(py$dfpic13, aes(x=年級, y=該學期通識修課比例, fill=是否被二一))+ geom_boxplot( outlier.shape = NA) + ylim(0,1)+labs(x='學期',y = "該學期通識修課比例",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
p4 <- ggplot(py$dfpic14, aes(x=年級, y=該學期共同必修修課比例, fill=是否被二一))+ geom_boxplot( outlier.shape = NA) + ylim(0,1)+labs(x='學期',y = "該學期共同必修修課比例",size=10) + scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8,face="bold"))+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```
```{r 10, results="asis" }
multiplot(p1,p2,p3,p4,cols=2)
```

圖10中，除了該學期選修修課比例可以看出中位數擁有較明顯的差異外，其餘變數相對來說看不出趨勢為何，故推論，修課的繁重程度對於學生的影響沒有太明顯，作為一個好的預測變數，必須能夠在兩類學生中清楚得看出差異，而該期選修修課比例在此方面表現良好，故僅放入選修修課比例作為預測變數。

綜合以上皆在討論成績與修課方面的特徵，而研究顯示，同儕對於學生學習也存有很大的關係，下小節將討論同儕面向所帶來的影響。

#### 群聚指標解釋變數

被二一的學生除了成績上的原因以外，也很有可能是心理層面上的問題，部分被二一的學生會想逃避同儕間所帶來的壓力，有意的安排，使自己不與班上同學修相同的課程，亦或是此類學生於班上的活躍度較低，與班上同學脫節，時常一人修課，而非跟著團體選擇修課，導致他所修的課程與大部分的同學皆不同。而此心理層面的資料較為敏感，也取得不易，故藉由以下所建立的特徵，試圖捕捉學生心理層面的狀態。

群聚指標是一個反應某位同學與班上同學間交集頻率的指標；其定義為，於學期結束後，所修的課裡分別有幾位班上同學一同修課，將其依依加總得到此指標。
累積群聚指標與前面小節的累積特徵概念較為不同，因於學期初時可以清楚的知道哪些同學有修相同的課程，故可計算當期的群聚指標，累積群聚指標是指累積至預測當期（包含預測當期）的群聚指標，群聚指標會受到各班各系修課數、畢業學分影響；在此分別以各班平均以及標準差，標準化此指標。

```{python}
dfpic9['是否被二一']=dfpic9['是否被二一'].astype(str)
dfpic9 = dfpic9[dfpic9['年級'] != '11']
```
```{r 12,results='asis',warning=FALSE}
ggplot(py$dfpic9, aes(x=年級 , y=累積標準化群聚指標, fill = 是否被二一)) + 
    geom_boxplot( outlier.shape = NA)+ scale_fill_manual(name='是否被二一',values=c("#40E0D0", "#FF7F50"))+labs(x='年級',y = "累積標準化群聚指標",size=10)+ scale_x_discrete(labels = c(2,3,4,5,6,7,8))
```

圖12顯示隨著年級上升兩類型學生的差異有越來越大的趨勢，主因為被二一的學生到後期必須去補足以前被當的科目而會導致與同班同學的課脫節，進而影響此特徵。

#### 綜合資料觀察

針對以上萃取出的變數進行相關性的觀察，並於此節對上述所有特徵整理說明。

```{r 13,results='asis',message=FALSE}
ggcorr(py$dfpic99,geom="circle", size = 2)
```

由圖13顯示，可以清楚看到，累積排名特徵之間相互具有正相關，其中又以累積專業必修排名與累積選修排名兩者之間的相關程度最高，而兩者又分別代表本系專業知識的程度與在更深入專業知識中的程度，通常各系畢業學分中，對於外系選修的學分承認是具有上限的，故選修課程中大部分仍為本系專業課程，若一位學生於本系的專業科目中表現良好，那麼他在更深入的專業科目中也可以得到較好的成績。
各類累積排名特徵間的正相關以及各類累積被當比之間的正相關，反應了整體成績表現是會同上同下的，若一位學生對於大學的教育產生了不適應，那麼在整體表現上皆會同時下降，故若能透過預測學生二一行為，儘早使校方採取預防措施，對於學校整體的教學是有利的。
綜合以上所有特徵的整理，首先我們觀察了過去被二一的次數，了解學生於未來時被二一的狀況，接著利用累積被當比來觀察一位學生於各類課程中的不適應狀況，然後更進一步利用累積排名特徵，了解學生程度差異的狀況，最後加入預測當期的課程繁重程度與學生心裡層面上的衡量指標，而所建的特徵中，兩類學生皆存在著差異性，皆為不錯的預測特徵。

# 研究方法

## 分類問題

對於學生i，給定預測二一特徵$x_i$，要如何產生預測結果$\hat{y}_i$，不同預測分類工具可從「模型設定」、「模型估計訓練方式」、及「預測使用方式」來區分說明。

## 模型

本文將使用四種機器學習方法對學生被二一的狀況進行預測，分別為羅吉斯回歸、隨機森林、支持向量機以及人工神經網路，以下依依介紹：

### 羅吉斯回歸 Logistic regression

模型設定：

$$
p_i=\Pr(Y_i=1|X_i)=\frac{\exp(\beta'x_i)}{1+\exp(\beta'x_i)}
$$

模型估計訓練方式：

估計方式為使用最大概似估計法，其求極值之目標函數為下

$$
max_{\beta} \sum_{i\in \mathcal{S}_{train}} \{ y_i \log p_i+(1-y_i)\log(1-p_i) \}
$$

$$
\hat{p}_i=\frac{\exp(\hat{\beta}'x_i)}{1+\exp(\hat{\beta}'x_i)}
$$

預測使用方式：

$$
 \hat{y}_i =
  \begin{cases}
    1       & \text{if } \hat{p}_i \geq \hat{c}\\
    0  & \text{otherwise.} 
  \end{cases}
$$

 $hat{c}$ 為門檻值，若預測出的機率高於此門檻值便顯示為被二一，若低於則為沒被二一。

### 決策樹

模型設定：一連串的樹狀決策結構，從根結點出發開始一連串由單一特徵變數所形成的「是/否」分枝，一直下去直到判斷出所屬分類。

example：

"過去是否有二一" 

  * 是：預測會二一

  * 不：預測不會二一

模型估計訓練方式：

  每一筆資料依決策樹分類後，會落在其中一個葉結點，因此每個葉結果會搜集到一群資料。完美的分類必需是每個葉結點資料群都是同類的，即都被二一或都不被二一，因此，對於一棵決策樹可計算它每個葉節點群的異類混雜程度，即不純度的概念，接著再進一步去考慮要不要對某個葉節點改成特徵變數子結點，進一步分類，以降低整體的不純度，直到不純度夠低為止。

預測使用方式：

圖14與圖15為示意圖。

<img src = https://imgur.com/zd57LSs.jpg>

圖14中，右側葉節點的正確機率為0.8，代表此葉節點的資料中，有八成的資料為被二一資料，模型經過不純度計算之後發現已夠低，便會停止往下分裂節點。左側之子節點裡，資料中沒被二一的比例僅有0.24，故會繼續往下伸出節點，直到節點中的不純度夠低為止。

<img src = https://imgur.com/FU018DM.jpg>

圖15中，左側子節點，繼續向下分裂，分裂出的兩個葉節，且不純度都以達到夠低，此時將停止分裂。


### 隨機森林

隨機森林由 Breiman Leo（2001）所提出，其基本原理為結合多棵決策樹，並加入隨機分配的訓練資料，以大幅增進最終的運算結果，此方法為Ensemble Method（集成方法）的一類，其想法為如果單個分類器表現不錯，那麼將多個分類器組合起來，其表現會優於單個分類器，建構模型的步驟為:

1.決定隨幾森林中需要多少棵樹，Hoerl A.E. and Kennard. R.W（1970）個數推薦約64~128，假設為K棵樹。

2.利用Bagging方式建造K棵決策樹，Bagging於1996年由Breiman提出（Bootstrap aggregating），此種方法會從訓練集中隨機抽取K個樣本集，並且取後放回，再從這K個樣本集中訓練出K棵數。

3.由K棵決策樹共同預測應變數，出現最多的類別則預測為該類。

隨機森林的建構模型的方法是生成很多棵決策樹，由這些決策樹的結果去投票得出最終預測，其中這些決策樹必須有所差異，除了使用Bagging的方式讓K棵決策樹有所差異，在隨機森林的決策樹生成時，也可從總變數中隨機抽取q個變數來當作此樹的分割變數，造成樹之間的差異性。

### 支持向量機

模型設定： 

$$
f(x_i|w,b)=w^Tx_i+b
$$

模型估計訓練方式：

若訓練資料可被特徵變數超平面完美區隔成2類，則為線性可分，其訓練過程在於：

$$
\begin{array}{lcl}
max_{w,b} & & margin(w,b)\\
s.t. & & y_i(w^Tx_i+b)>0 \mbox{ for }i\in\mathcal{S}_{train}
\end{array}
$$

若訓練資料不可被特徵變數超平面完美區隔成2類，則為線性不可分，會利用kernel function 於下式中以K表示，此時訓練過程為：

$$
\begin{array}{lcl}
max_{w,b} & & margin(w,b)\\
s.t. & & y_i(w^TK(x_i+b))>0 \mbox{ for }i\in\mathcal{S}_{train}
\end{array}
$$

預測使用方式：

$$
\hat{y}_i =
  \begin{cases}
    1       & \text{if } f(x_i|w,b)=w^Tx_i+b \geq 0\\
    0  & \text{otherwise.} 
  \end{cases}
$$

若 $f(x_i|w,b)=w^Tx_i+b \geq 0$ 則預測為被二一。

### 人工神經網路 Artificial Neural Network (ANN) 

模型設定：

$$
\begin{array}{lcl}
x_i(K\times1) &\stackrel{g}{\rightarrow} & n_i(M\times 1)\\
n_i(M\times 1) &\stackrel{f}{\rightarrow} & p_i(1\times 1)
\end{array}
$$

其中

$$
g(x_i)=
\begin{bmatrix}
g_1(x_i) \\
g_2(x_i) \\
\vdots \\
g_M(x_i)
\end{bmatrix}=
\begin{bmatrix}
a(w_1'x_i+b_1)\\
a(w_2'x_i+b_2)\\
\vdots\\
a(w_M'x_i+b_M)
\end{bmatrix}=
\begin{bmatrix}
n_{1,i}\\
n_{2,i}\\
\vdots\\
n_{M,i}
\end{bmatrix}=n_i
$$

函數a(z)一般稱為激活函數，用來控制z是否輸出，常用的函數型態為$a(z)=max(0,z)$; 此外, 我們選定$f(z)$為一logistic函數:

$$
f(n_i)=\frac{\exp(\beta'n_i)}{1+\exp(\beta'n_i)}
$$

模型估計訓練方式：

$$
max_{\textbf{w,b},\beta} \sum_{i\in \mathcal{S}_{train}} \{ y_i \log p_i+(1-y_i)\log(1-p_i) \}
$$

## 資料集

本文將資料分割成兩個資料集，訓練集以及測試集分別佔總資料70%與30%，測試集僅於最後選定模型之後套入模型使用，訓練集主要為訓練分類器；並透過10疊交叉驗證集來訓練超參數。
參數與超參數的區別為，參數是指選定的機器學習技術中用來調整資料的變數；如本文所使用支持向量機中的 $w_i$ ，超參數與訓練資料沒有直接關聯屬於設定變數，參數在訓練時會不斷修正而超參數並不會改變；如本文所使用支持向量機中的 $C,\gamma$ ，而如何得到更好得超參數一個方法為運用驗證集來調整，由訓練集訓練不同的超參數得出模型後再丟入驗證集做驗證，藉此來調整超參數。

## Synthetic Minority Over-sampling Technique

不平衡資料指的是資料中類別的不平均，以本文訓練集資料為例，被二一資料筆數為322筆，而訓練集資料總筆數為2萬8千270，故本文所使用資料為不平衡資料，若是以總體分類準確率為學習目標的傳統分類演算法會將預測重點放於多數類，從而使得少數類樣本的分類效能下降，故絕大多數常見的機器學習演算法對於不平衡資料集都不能很好的分類。本文使用Synthetic Minority Over-sampling Technique簡稱為SMOTE（Chawla,Bowyer,Hall and Kegelmeyer,2002）方法以解決此問題，其出發點為，減少沒被二一類的樣本，並且增加被二一類樣本數。

增加被二一類樣本的建法步驟如下：

1.  對於被二一類中每一個樣本點 $y_i$ ，將各特徵以[3]歐氏距離為標準，分別計算它到被二一類樣本集 $S_{被二一}$ 中所有樣本的距離，然後得到每個樣本點中最近的5個樣本點。

2.  對於每一個被二一類樣本 $y_i$ ，從其5個近鄰中隨機選擇1個樣本，假設選擇的近鄰為 $\hat{y_i}$ 。

3.  對於每一個隨機選出的近鄰 $\hat{y_i}$ ，分別與原樣本按照如下的公式構建新的樣本，最後將所有新合成的樣本點加入資料中。

$$ y_{i,new} = y_i + rand(0,1)(\hat{y_i} -y_i)  $$

而沒被二一類資料點則是採隨機丟取，直到與被二一類新的資料筆數相同為止。

## 模型預測表現衡量

目前對於演算法模型評價的指標又很多如：召回率、準確度、F值、Area Under Curve （AUC）、R square等，多數應用於教育資料探勘文獻中的指標為準確度與AUC，兩者評價指標之間的抉擇，Bradle於1997年文獻中進行了比較；文中表示我們應優先選擇AUC應用於機器學習中預測結果的評價，主要可以依據下列理由，準確度會因為不同的閥值而導致有不同的結果而AUC是各閥值所連起的線下面積；故AUC不會受到閥值選擇的影響，在陽性資料與陰性資料差距很大時AUC擁有著比準確度還好的評價功能，例如當一筆資料中陰性類的樣本佔大多數時，面臨所有陰性樣本預測成功而陽性樣本預測失敗的情況，其準確度仍可以以達到很高，這代表了在這筆資料中準確度忽略了陽性樣本的重要性，而AUC可以解決此類問題，針對分類完美的模型AUC可以給出較高的評價，而對於僅能成功預測出單一類型的模型給予較低的評價。

$$
\frac{True Positive + True Negative}{True Positive + True Negative + False Positive +False Negative}
$$

以下將True Positive、True Negative、False Positive、False Negative簡稱為TP、TN、FP、FN 。然而當資料為不平衡資料；如本文資料中沒被二一類的資料遠高於被二一類，即Positive類較少，即使分類器將全部的資料都遇測為沒被二一類（Negative），其準確度仍可以達到很高，故本文分類器驗證指標將使利用AUC來作為評價標準，以下將介紹AUC衡量指標為何。

<img src= https://imgur.com/6Kkkinq.jpg>

早期Receiver operating characteristic curve （ROC曲線）主要利用於生物醫學上，後也開始被廣泛使用於機器學習，在相關的驗證研究的文獻當中，ROC曲線可謂最常被使用來驗證整體模型效度之方法，透過調整其閥值來衡量分類正確與錯誤的次數，藉此來呈現二一學生捕捉率（在文獻中稱為敏感度），與誤查率之間的抵換關係，ROC曲線橫軸為誤查率，縱軸為二一學生捕捉率，二一學生捕捉率定義為 $\frac{TP}{TP+ FN}$ ，所刻畫的是分類器所分類出的被二一占實際上被二一的比例，誤查率定義為 $\frac{FP}{FP+ TN}$ ，刻劃的是分類器分類出沒被二一的學生卻被誤人為被二ㄧ，占實際為沒被二一生的比例。
此兩指標具有抵換關係，假設原模型被視為正例的閥值為0.5，即模型預測該點為正例的機率大於0.5便為正例，反之則為負例。如果減少閥值至0.1，則能識別出更多正例，也就是提高了二一學生捕捉率，但同時也會將更多的負例預測為正例，即降低了誤查率，在統計學上又將FP稱為「型一錯誤」，FN稱為「型二錯誤」。
模型在訓練各種不同的閥值時，會分別有各自的一組二一學生捕捉率與誤查率，將其各點的二一學生捕捉率與誤查率繪於圖上行形成ROC 曲線，隨著閥值的遞增，二一學生捕捉率和所對應的誤查率均會呈現遞增狀況。

<img src= https://imgur.com/Nf33eAD.jpg>

<img src= https://imgur.com/HKOz5GG.jpg>

ROC曲線提供了一個方便觀察模型優劣的方法，首先觀察ROC曲線圖的幾個點；若為（0,0）則代表該分類器會預測所有樣本皆為負例，（1,1）則是將其全數預測為正例，（0,1）代表的是將所有的樣本都正確分類，（1,0）則為全樣本錯誤分類，可以得出ROC曲線若能向左上角靠則代表此分類器擁有越好的分類效果，當一個模型的預測能力完美時，ROC曲線會在左方與縱軸貼齊，上方與橫軸貼齊；ROC曲線越往左上則代表分類效果越好，而當ROC曲線貼合於從原點出發的對角線時，則代表此模型為隨機模型，即此模型沒有任何預測能力，而當ROC曲線之間出現交錯或難以觀察的狀況時，可藉由ROC曲線下的面積AUC（Area Under Curve）來評定分類器的好壞，即ROC曲線下的面積占整體橫縱軸所構成之四方形面積的比例，若為1代表完美模型，0.5則代表此模型毫無預測能力，一般模型此值皆介於0.5至1之間，若於0.5以下則代表該分類器具有相反的分類效果。

# 研究結果

## 模型結果

分別比較四個模型的AUC與觀察混於訓練集的混淆矩陣：


```{r,warning=FALSE,message=FALSE,error=FALSE}
#g1 <- ggplot(results1$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
 # geom_roc(n.cuts=0) + 
# # coord_equal() +
 #style_roc()+
 # labs(title='logistic')+
 # theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
 #       axis.title.x = element_text(size = 5),
 #       axis.title.y =  element_text(size = 5)) + 
#  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
#  scale_y_continuous(breaks=seq(0, 1, 0.5)) 
#g1 <- g1 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g1))$AUC, 2)),size=2)

#g2 <- ggplot(results2$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
#  geom_roc(n.cuts=0) + 
##  coord_equal() +
#  style_roc()+
 ## labs(title='logistic weight')+
#  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
#        axis.title.x = element_text(size = 5),
 #       axis.title.y =  element_text(size = 5)) + 
 # scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
 # scale_y_continuous(breaks=seq(0, 1, 0.5)) 
#g2 <- g2 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g2))$AUC, 2)),size=2)


g3 <- ggplot(results3$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
  geom_roc(n.cuts=0) + 
  coord_equal() +
  style_roc()+
  labs(title='logistic smote')+
  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
        axis.title.x = element_text(size = 5),
        axis.title.y =  element_text(size = 5)) + 
  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  scale_y_continuous(breaks=seq(0, 1, 0.5)) 
g3 <- g3 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g3))$AUC, 2)),size=2)

#g4 <- ggplot(results4$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
 # geom_roc(n.cuts=0) + 
 # coord_equal() +
 # style_roc()+
 # labs(title='logistic over')+
 # theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
  #      axis.title.x = element_text(size = 5),
  #      axis.title.y =  element_text(size = 5)) + 
  #scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
 # scale_y_continuous(breaks=seq(0, 1, 0.5)) 
#g4 <- g4 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g4))$AUC, 2)),size=2)

#g5 <- ggplot(results5$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
 # geom_roc(n.cuts=0) + 
 # coord_equal() +
#  style_roc()+
#  labs(title='logistic under')+
 # theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
 #       axis.title.x = element_text(size = 5),
 #       axis.title.y =  element_text(size = 5)) + 
 # scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
 # scale_y_continuous(breaks=seq(0, 1, 0.5)) 
#g5 <- g5 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g5))$AUC, 2)),size=2)

#g6 <- ggplot(results6$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
#  geom_roc(n.cuts=0) + 
#  coord_equal() +
 # style_roc()+
 # labs(title='logistic both')+
 # theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
       # axis.title.x = element_text(size = 5),
       # axis.title.y =  element_text(size = 5)) + 
  #scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  #scale_y_continuous(breaks=seq(0, 1, 0.5)) 
#g6 <- g6 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g6))$AUC, 2)),size=2)

g7 <- ggplot(resultsrf$pred, aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
  geom_roc(n.cuts=0) + 
  coord_equal() +
  style_roc()+
  labs(title='random forest')+
  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
        axis.title.x = element_text(size = 5),
        axis.title.y =  element_text(size = 5)) + 
  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  scale_y_continuous(breaks=seq(0, 1, 0.5)) 
g7 <- g7 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g7))$AUC, 2)),size=2)

g8 <- ggplot(resultssvm$pred,aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
  geom_roc(n.cuts=0) + 
  coord_equal() +
  style_roc()+
  labs(title='svm')+
  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
        axis.title.x = element_text(size = 5),
        axis.title.y =  element_text(size = 5)) + 
  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  scale_y_continuous(breaks=seq(0, 1, 0.5)) 

g8 <- g8 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g8))$AUC, 2)),size=2)

g9 <- ggplot(resultsnnet$pred,aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
  geom_roc(n.cuts=0) + 
  coord_equal() +
  style_roc()+
  labs(title='ANN')+
  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
        axis.title.x = element_text(size = 5),
        axis.title.y =  element_text(size = 5)) + 
  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  scale_y_continuous(breaks=seq(0, 1, 0.5)) 

g9 <- g9 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g9))$AUC, 2)),size=2)

g10 <- ggplot(resultslog$pred,aes(m=yes, d=factor(obs, levels = c("no", "yes")))) + 
  geom_roc(n.cuts=0) + 
  coord_equal() +
  style_roc()+
  labs(title='ANN')+
  theme(plot.title=element_text(face="bold",size=5,hjust = 0.5),
        axis.title.x = element_text(size = 5),
        axis.title.y =  element_text(size = 5)) + 
  scale_x_continuous(breaks=seq(0, 1, 0.5)) + 
  scale_y_continuous(breaks=seq(0, 1, 0.5)) 

g10 <- g10 +  annotate("text", x=0.75, y=0.25, label=paste("AUC =", round((calc_auc(g10))$AUC, 2)),size=2)
```

```{r 15,results='asis',warning=FALSE,message=FALSE,error=FALSE}
multiplot(g3,g7,g8,g9,cols=2)
#第四張圖是使用Oversampling，會將少類的觀測值隨機重複，train data多類樣本的數目為28256，故也將少類的資料筆數重複讀直到相同筆數。（此方法缺陷為過度擬合，會過度放大少類噪音的影響）第五張圖是使用Undersampling中的Random，隨機刪除多類的數據直到多類跟少類相同為止。（缺點可能刪去太多重要資訊）第六張圖是使用Oversampling與Undersampling兩種方法合併，少類Oversampling，多類Undersampling
```

<img src = https://imgur.com/a/64PE7Nv.jpg>

圖19中顯示，AUC中最高的為隨機森林模型，其值高達0.93，從四個模型於訓練集的混淆矩陣，可知人工神經網路模型，僅能有效判別預測為被二一，而其餘三者皆達到很好的效果。
隨機森林的二一學生捕捉率與準確度都高達99.7%其值最高，支持向量機、羅吉斯迴歸以及人工神經網路的二一學生捕捉率也分別得到0.84、0.81與0.79，由以上結果可知，隨機森林不管是在各方面皆表現最好，故將使用隨機森林於測試集資料中進行測試。
隨機森林模型於測試集資料進行預測後，結果如圖20，誤查率僅有0.16，因是不平衡資料，所以準確度應看Balanced Accuracy 即 $\frac{(\frac{TP}{TP+FN}+\frac{TN}{TN+FP})}{2}$ ，其 Balanced Accuracy 為0.815，二一學生捕捉率也有高達0.787，代表實際被二一的同學中，模型可以成功預測出被二一的比例高達79%左右，綜合以上本模型在於預測學生被二一有著很好的預測效果。

<img src = https://imgur.com/n5F1CJj.jpg>

## 變數重要性衡量

得知隨機森林為以上幾個中最好的分類器後，利用特徵經過置換前與置換後的誤差影響，來衡量各特徵的重要性。
結果如圖21所示，觀察解釋能力前三的變數，累積專業必修排名、累積專業必修被當比、累積選修排名；最為重要，而專業必修與選修所代表的是本系的專業知識，說明專業性的知識對於學生是否會被二一的影響程度是最大的，而從圖13得知，累積專業必修排名、累積選修排名分別與累積共同必修排名具有高度的正相關，這也表明學生於大學生活上的適應狀況與專業領域的培養之間擁有正向的關係，故若可以提高學生在專業領域的表現或許也可以使學生在大學的適應狀況提升。

```{r,results='asis',message=FALSE,error=FALSE,warning=FALSE}
qq<- varImp(resultsrf)
library(mlbench)
library(tidyverse)
varImp(resultsrf)$importance %>% 
  as.data.frame() %>%
  rownames_to_column() %>%
  arrange(Overall) %>%
  mutate(rowname = forcats::fct_inorder(rowname )) %>%
  ggplot()+
    geom_col(aes(x = rowname, y = Overall))+
    coord_flip()+
    theme_bw()
```


# 結論與建議

## 結論

本文分別利用了四種分類器，分別為羅吉斯回歸、隨機森林、支持向量機以即人工神經網路，預測學生未來的二一狀況，結果顯示隨機森林在預測中表現早好；Balanced Accuracy為0.815，召回率為0.787，觀察變數間的重要性時發現本科專業知識的學習狀況對於一位學生未來是否會被二一有著很大的關係，而校方該如何提出一個完善的措施來提升學生專業知識的表現，改善學生的二一情形是學生與校方的重要課題。

## 建議

本文所利用成績單資料預測學生於未來時是否會被二一之表現雖得到不錯的效果，但許多時候學生是否會被二一也會由學生之心理狀況、學生出生背景；如父母職業，是否為明星高中，出生地人口密集程度，以及學生大學前成績表現等狀況影響，若未來想增強預測能力除了增加樣本資料外，亦可藉由此方向著手。

# 參考文獻

林士翔,2008,營造業違約邊界之研究

鄭媛文,2013,同儕教導學習策略對學生學習成就與情意態度影響之後設分析

[1]http://www.edtung.com/TopNews/NewsContent.aspx?no=2250

[2]吳東陽,2018,大學雙二一退學與學生行為

Xhttp://www.ettoday.net/news/20121119/129267.htm

X.C. J. C. Burges, “A tutorial on support vector machines for pattern recognition”, Data Mining and Knowledge Discovery, vol. 2, no. 2, pp.955-974 , 1998.

X. Schőlkopf, C. J. C. Burges & A. J. Smola, “Introduction to support vector
learning, advances in kernel methods-support vector learning,” Cambridge, MA, pp. 1-15,  1999.

Tinto, V. Limits of theory and practice in student attrition, Journal of Higher Education 53, p. 687-700, 1982. 

Alaa El-Halees, Mining Students Data to Analyze Learning Behavior: A Case Study, 2008.

Jiawei Han , Micheline Kamber, Data Mining: Concepts and Techniques, 2nd edition, 2006.

S. KOTSIANTIS,C. PIERRAKEAS,P. PINTELAS, PREDICTING STUDENTS'PERFORMANCE IN DISTANCE LEARNING USING MACHINE LEARNING TECHNIQUES ,Applied Artificial Intelligence, 18:411-426, 2004.

Schaffer,C., A conservation law for generalization performance. In Proceedings of the Eleventh International Conference on Machine Learning, Pages 153-178, New Brunswick, USA, July 10-13, 1994.

Ghadeer S. Abu-Oda and Alaa M. El-Halees, DATA MINING IN HIGHER EDUCATION : UNIVERSITY STUDENT DROPOUT CASE STUDY ,International Journal of Data Mining & Knowledge Management Process (IJDKP) Vol.5, No.1, January 2015 .

P. Baepler and C. J. Murdoch, "Academic Analytics and Data Mining in Higher Education," International Journal for the Scholarship of Teaching and Learning, vol. 4, no. 2, pp. 1-9, 2010. 

U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth and R. Uthurusamy, "Advances in knowledge discovery and data mining," 1996. 

R. S. J. D. Baker and K. Yacef, "The State of Educational Data Mining in 2009 : A Review and Future Visions," Journal of Educational Data Mining, vol. 1, no. 1, pp. 3-16, 2009.

A. AL-Malaise, A. Malibari and M. Alkhozae, "STUDENTS’ PERFORMANCE PREDICTION
SYSTEM USING MULTI AGENT DATA MINING TECHNIQUE," International Journal of Data
Mining & Knowledge Management Process (IJDKP) , vol. 4, 2014. 

B. Baradwaj and S. Pal, "Mining educational data to analyze student's performance," Internation Journal od Advamced Computer Science and Applications, vol. 2, no. 6, pp. 63-69, 2012.

Gerben W. Dekker1, Mykola Pechenizkiy2 and Jan M. Vleeshouwers1,Predicting Students Drop Out: A Case Study ,International Conference on Educational Data Mining (EDM) , 2nd, Cordoba, Spain, Jul 1-3, 2009.

Cortez, P., & Silva, A., Using data mining to predict secondary school student performanc, 2008.

Kotsiantis S., Pierrakeas C. and Pintelas P., Predicting Students’ Performance in Distance Learning Using Machine Learning Techniques. Applied Artificial Intelligence (AAI), 18, no. 5, 411–426, 2004.

Pyke, S. W., & Sheridan, P. M., Logistic regression analysis of graduate student retention.Canadian Journal of Higher Education,23, 44–64, 1993.

Fletcher, J., and Stren, R., Discussion of the factors influencing time to completion in graduate programs: Student views. In C. Filteau (ed.), Graduate Graduation Rates and Time to Completion: Colloquium Proceedings (pp. 17-48). Toronto: Council of Ontario Universities, 1992.

Andrew P Bradle, Pattern Recognition, 30(7), pp. 1145-1159, 1997.

Nitesh V. Chawla,Kevin W. Bowyer,Lawrence O. Hall,W. Philip Kegelmeyer,SMOTE: Synthetic Minority Over-sampling Technique,Journal of Artificial Intelligence Research 16 , 321–357, 2002.

Breiman, L., Friedman, J.H., Olshen, R.A., and Stone, C.J., Classification and
Regression Trees, Wadsworth, Belmont, CA. Republished by CRC Press, 1984.
 
Breiman, L., Random Forests. Machine learning, 45(1), 5-32, 2001.

Hoerl A.E. and Kennard. R.W. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(3):55-67, 1970.

S. R. Gunn, “Support Vector machines for classification and regression,” Technical
Repor,t University of Southampton, 1998. 

V.Vapnik.,Statistical Learning Theory ,John Wiley & Sons, New York, 1998.

V.Vapnik.,The Nature of Statistical Learning Theory,2nd edition, Springer- Verlag, New York, 1999.

C. W. Hsu, C. C. Chang & C. J. Lin, A practical guide to support vector
classification, 2003.

McCulloch W., Pitts W., A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathmetical, 5, 115-133, 1943.

Rumelhart D., McClelland J., Psychological and Biological Models, 1986.




# 附錄

變數重要性衡量算法：

1. 利用每棵樹的分類模型來預測自己的 Out-Of-Bag （OOB）樣本，並計算錯誤率。

  * OOB：在建構每棵樹的時候，我們對訓練集使用了不同的bootstrap sample。所以對於每棵樹而言，大约有1/3的資料點是沒有參與該棵樹的生成，他們就是該棵樹的OOB样本。

2. 對想了解該特徵重要性的特徵進行隨機打亂。

3. 利用原隨機森林模型進行預測得到新的預測值。

4. 計算每棵樹新的OOB樣本錯誤率。

5. 對於每棵樹擾亂特徵前後所得到的錯誤率相減並平均。

6. 得出因該特徵擾亂後而導致的平均誤差上升多少，越高代表該變數越重要。
```{python}
aa=df[df['學號'] == 410080053]
```


[3]歐氏距離：

n為各特徵值。

$$
Distance_{1,2}= \sqrt{\sum_{k=1}^n(x_{1k}-x_{2k})}
$$

$$
f(net_i) = f(\sum_i w_{ij}x_i - \theta_i) 
$$

$w_{ij}$ 為類神經網路處理理單元間的連結權重值， $x_i$ 為輸入值，$\theta_i$ 為神經元的 門檻值。

倒傳遞類神經網路學習演算法中主要的學習過程為從樣本中學習以及不斷的調整網路連結權重值的過程；其中分為兩部份，第一部分為向前傳遞；另一部分為向後傳遞，步驟為輸入層輸入資料向前傳遞，經權重處理後經過隱藏層，再經一個激活函數得到輸出值，如下圖，最後將輸出值與真實值帶入代價函數(Cost function)中，並極小化代價函數 $J=-y * log×(\hat{y}) − (1−y)×log(1−\hat{y})$ ，反向傳遞的部分為利用梯度下降法調整權重。經由不斷反覆向前以及向後傳遞的過程反覆訓練，直至產生一組最佳的權重值 $w_{ij}$ 。

<img src = https://imgur.com/13qRWcV.jpg>

























